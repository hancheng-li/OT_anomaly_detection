{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "from numpy.random import Generator, PCG64\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/bobli/Dropbox/AnomalyDetection/OnML4Jets2021DataChallenge/anomaly_detection_code/functions/')\n",
    "from centralFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigAliasList    = ['sig_A', 'sig_h0', 'sig_hch', 'sig_LQ']\n",
    "sigFilenameList = ['Ato4l_lepFilter_13TeV_filtered.h5', 'hToTauTau_13TeV_PU20_filtered.h5', 'hChToTauNu_13TeV_PU20_filtered.h5', 'leptoquark_LOWMASS_lepFilter_13TeV_filtered.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Set base directory and data directory path --#\n",
    "# basePath   = '/Users/hanchengli/Dropbox/AnomalyDetection/OnML4Jets2021DataChallenge/'\n",
    "basePath   = '/Users/bobli/Dropbox/AnomalyDetection/OnML4Jets2021DataChallenge/anomaly_detection_code/'\n",
    "dataPath   = 'data/ADC2021/'\n",
    "\n",
    "bkgPath    = basePath+dataPath+'background_for_training.h5'\n",
    "sigPathList = []\n",
    "for x in sigFilenameList:\n",
    "  sigPathList.append(basePath+dataPath+x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDict = {}\n",
    "dataDict['bkg'] = h5py.File(bkgPath, 'r')\n",
    "\n",
    "for i in range(len(sigAliasList)):\n",
    "  alias   = sigAliasList[i]\n",
    "  sigPath = sigPathList[i]\n",
    "  dataDict[alias] = h5py.File(sigPath, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_data = dataDict['bkg']['Particles'][:, :, 0:3]\n",
    "sig_data = {}\n",
    "\n",
    "for alias in sigAliasList:\n",
    "  sig_data[alias] = dataDict[alias]['Particles'][:, :, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Class SVM on 3D Ground Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 1000\n",
    "train_size = 10000\n",
    "random_state = Generator(PCG64(1))\n",
    "np.random.seed(100)\n",
    "OTSCHEME = {}\n",
    "OTSCHEME['normPT'] = False\n",
    "OTSCHEME['balanced'] = True\n",
    "OTSCHEME['noZeroPad'] = False\n",
    "OTSCHEME['individualOT'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_events = randomDataSample(bkg_data, train_size + test_size * 6, random_state)\n",
    "sig_events = {}\n",
    "for alias in sigAliasList:\n",
    "    sig_events[alias] = randomDataSample(sig_data[alias], test_size * 6, random_state)\n",
    "\n",
    "train_events = bkg_events[:train_size]\n",
    "test_events = []\n",
    "\n",
    "val_events = []\n",
    "val_events.extend(bkg_events[train_size+test_size*5:])\n",
    "for alias in sigAliasList:\n",
    "    val_events.extend(sig_events[alias][test_size*5:])\n",
    "val_events = np.asarray(val_events)\n",
    "for i in range(0, 5):\n",
    "    test_events.append({})\n",
    "    test_events[i]['bkg'] = bkg_events[train_size+test_size*i:train_size+test_size*(i+1)]\n",
    "    for alias in sigAliasList:\n",
    "        test_events[i][alias] = sig_events[alias][test_size*i:test_size*(i+1)]\n",
    "    \n",
    "del bkg_data, sig_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_matrix = calcOTDistance(train_events, train_events, OTSCHEME, '3D', Matrix=True)\n",
    "# filePath = '/Users/hanchengli/Dropbox/AnomalyDetection/OnML4Jets2021DataChallenge/Data/train_matrix_10k.npy'\n",
    "filePath = '/Users/bobli/Dropbox/AnomalyDetection/OnML4Jets2021DataChallenge/anomaly_detection_code/data/train_matrix_10k.npy'\n",
    "train_matrix = np.load(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = np.asarray([1] * test_size + [-1] * test_size * 4)\n",
    "nu = 0.2\n",
    "gamma_list = [0.05, 0.15, 0.25, 0.35, 0.45, 0.55]\n",
    "auc_list = []\n",
    "val_matrix = parallel_OT_non_square(val_events, train_events, OTSCHEME, '3D')\n",
    "for gamma in gamma_list:\n",
    "    auc, f1_score, _ = OneClassSVM_with_distance_matrix(train_matrix, val_matrix, val_labels, gamma, nu)\n",
    "    auc_list.append(auc)\n",
    "    \n",
    "max_index = auc_list.index(max(auc_list))\n",
    "gamma = gamma_list[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.asarray([1] * test_size + [-1] * test_size * 4)\n",
    "\n",
    "best_aucs = {}\n",
    "\n",
    "aucs = np.zeros((5,4))\n",
    "\n",
    "f1_scores = np.zeros((5,4))\n",
    "\n",
    "ROC_metrics = {}\n",
    "\n",
    "for j in range(0, 5):\n",
    "    test_set = []\n",
    "    test_set.extend(test_events[j]['bkg'])\n",
    "    ROC_metrics['repeat'+str(j)] = {}\n",
    "    for alias in sigAliasList:\n",
    "        test_set.extend(test_events[j][alias])\n",
    "    test_set = np.asarray(test_set)\n",
    "    test_matrix = parallel_OT_non_square(test_set, train_events, OTSCHEME, '3D')\n",
    "    for i, alias in enumerate(sigAliasList):\n",
    "        specific_test_labels = np.concatenate((test_labels[0:test_size], test_labels[test_size * (i+1):test_size * (i+2)]))\n",
    "        specific_test_matrix = np.concatenate((test_matrix[0:test_size, :], test_matrix[test_size * (i+1):test_size * (i+2), :]))\n",
    "        auc, f1_score, ROC_metrics['repeat'+str(j)][alias] = OneClassSVM_with_distance_matrix(train_matrix, specific_test_matrix, specific_test_labels, gamma, nu)\n",
    "        \n",
    "        aucs[j, i] = auc\n",
    "        f1_scores[j, i] = f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_aucs = {}\n",
    "std_aucs = {}\n",
    "\n",
    "for i, alias in enumerate(sigAliasList):\n",
    "    mean_aucs[alias] = np.mean(aucs, axis=0)[i]\n",
    "    std_aucs[alias] = np.std(aucs, axis=0)[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_f1_scores = {}\n",
    "std_f1_scores = {}\n",
    "\n",
    "for i, alias in enumerate(sigAliasList):\n",
    "    mean_f1_scores[alias] = np.mean(f1_scores, axis=0)[i]\n",
    "    std_f1_scores[alias] = np.std(f1_scores, axis=0)[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bobli/Library/CloudStorage/Dropbox/AnomalyDetection/OnML4Jets2021DataChallenge/anomaly_detection_code/experiments/OT_ML/OT_oneClassSVM\n"
     ]
    }
   ],
   "source": [
    "transposed_dict = {\n",
    "    col: {row: ROC_metrics[row][col] for row in ROC_metrics}\n",
    "    for col in ROC_metrics[next(iter(ROC_metrics))]\n",
    "}\n",
    "# Convert NumPy arrays in the lists to regular lists\n",
    "converted_dict = {\n",
    "    row: {\n",
    "        col: [transposed_dict[row][col][0]] + [arr.tolist() for arr in transposed_dict[row][col][1:]]\n",
    "        for col in transposed_dict[row]\n",
    "    }\n",
    "    for row in transposed_dict\n",
    "}\n",
    "%cd ~/Dropbox/AnomalyDetection/OnML4Jets2021DataChallenge/anomaly_detection_code/experiments/OT_ML/OT_oneClassSVM\n",
    "with open('OneClassSVM.json', 'w') as json_file:\n",
    "    json.dump(converted_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_dict = {}\n",
    "for i, alias in enumerate(sigAliasList):\n",
    "    f1_scores_dict[alias] = {}\n",
    "    for j in range(0, 5):\n",
    "        f1_scores_dict[alias]['repeat'+str(j)] = f1_scores[j, i].tolist()\n",
    "\n",
    "with open('OneClassSVM_f1_scores.json', 'w') as json_file:\n",
    "    json.dump(f1_scores_dict, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
