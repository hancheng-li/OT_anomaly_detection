{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9Ag7aRGHD5u"
   },
   "source": [
    "This notebook centrally defines the various functions that are used for plotting, handling data, and calculating OT distances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UpoaxeIHQzd"
   },
   "source": [
    "Summary of function names and descriptions (TBD):\n",
    "\n",
    "**Data handling functions:**\n",
    "\n",
    "*   List item\n",
    "*   List item\n",
    "\n",
    "\n",
    "**Plotting functions:**\n",
    "\n",
    "*   List item\n",
    "*   List item\n",
    "\n",
    "**OT calculating functions:**\n",
    "\n",
    "*   List item\n",
    "*   List item\n",
    "\n",
    "**Machine learning functions:**\n",
    "\n",
    "* List item\n",
    "* List item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzPInTTSYm2D"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xGErkTwocw1"
   },
   "source": [
    "We'll eventually be using the PyOT library to compute Wasserstein distances for now (see [here](https://pythonot.github.io/index.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17943,
     "status": "ok",
     "timestamp": 1693449818964,
     "user": {
      "displayName": "Hancheng Li",
      "userId": "16561302137020690535"
     },
     "user_tz": 420
    },
    "id": "q-55fN2QHrsq",
    "outputId": "54d8b4af-4569-48e8-9a92-c7ff0055d015"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import numpy.ma as ma\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "%matplotlib inline\n",
    "\n",
    "import h5py\n",
    "import ot\n",
    "from numpy.random import Generator, PCG64\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn import svm\n",
    "import concurrent.futures as cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-zeI8htLCVt"
   },
   "source": [
    "# OT calculating functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0WhCombNy6Q"
   },
   "source": [
    "#### `calcGroundCostMatrix()`\n",
    "\n",
    "Also contains\n",
    "- `calcGroundCostMatrix_1DpT()`\n",
    "- `calcGroundCostMatrix_2D()`\n",
    "- `calcGroundCostMatrix_3D()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "G7XCF_EiRKyM"
   },
   "outputs": [],
   "source": [
    "def calcGroundCostMatrix(xs, xt, COSTSCHEME):\n",
    "  \"\"\"\n",
    "  Calculate ground cost matrix between xs and xt\n",
    "\n",
    "  Inputs:\n",
    "             xs:  3D (pT, eta, phi) coordinates of nx source particles (shape=(nx,3));\n",
    "                  nx = number of entries in xEvents\n",
    "             xt:  3D (pT, eta, phi) coordinates of ny source particles (shape=(ny,3));\n",
    "                  ny = number of entries in yEvents\n",
    "     COSTSCHEME:  Determines what scheme will be used to calculate the ground cost matrix. Options are:\n",
    "                  - 1DpT: Ground space is pT only\n",
    "                  - 2D:   Ground space is 2D (eta,phi); note mass is pT\n",
    "                  - 3D:   Ground space is 3D (pT,eta,phi); note mass is uniform\n",
    "\n",
    "  Output:\n",
    "     Returns matrix of pair-wise |x - y|^2 distances\n",
    "\n",
    "  \"\"\"\n",
    "  if COSTSCHEME=='1DpT':\n",
    "    return calcGroundCostMatrix_1DpT(xs, xt)\n",
    "  elif COSTSCHEME=='2D':\n",
    "    return calcGroundCostMatrix_2D(xs, xt)\n",
    "  elif COSTSCHEME=='3D':\n",
    "    return calcGroundCostMatrix_3D(xs, xt)\n",
    "  else:\n",
    "    print(\"Error: Invalid COSTSCHEME\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wa-CSjeUijlJ"
   },
   "source": [
    "##### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gX0KC5vDLyX_"
   },
   "outputs": [],
   "source": [
    "def calcGroundCostMatrix_1DpT(xs, xt):\n",
    "  \"\"\"\n",
    "  Auxiliary function, assumes ground space is pT only\n",
    "  \"\"\"\n",
    "  deltaPT      = xs[:,0,None] - xt[:,0]\n",
    "  return deltaPT**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8gj9PezUvua"
   },
   "source": [
    "Note: The following functions were modified from Tianji's code below:\n",
    "\n",
    "```\n",
    "d_phis = np.pi - np.abs(np.pi - np.abs(jet1_coords[:,1,None]-jet2_coords[:,1]))\n",
    "squareDist = (jet1_coords[:,0,None]-jet2_coords[:,0])**2 + d_phis**2\n",
    "```\n",
    "\n",
    "But also note that according to [this thread](https://stackoverflow.com/questions/1878907/how-can-i-find-the-smallest-difference-between-two-angles-around-a-point), this way of calculating modular differences may fail if deltaPhi_raw > 360 deg (2 pi)\n",
    "However, since the input is between -pi and pi, the max possible is 2pi so it shouldn't be a problem. It is also unsigned, however since we will square it that doesn't matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hlGHpzNxRGnL"
   },
   "outputs": [],
   "source": [
    "def calcGroundCostMatrix_2D(xs, xt):\n",
    "  \"\"\"\n",
    "  Auxiliary function, assumes ground space is eta,phi.\n",
    "  phi is 2pi modular which must be taken into account when computing the matrix of\n",
    "  pair-wise |x - y|^2 distances\n",
    "  \"\"\"\n",
    "  deltaEta     = xs[:,1,None] - xt[:,1]\n",
    "  deltaPhi_raw = xs[:,2,None] - xt[:,2]\n",
    "  deltaPhi     = np.pi - np.abs(np.pi - np.abs(deltaPhi_raw))\n",
    "  return deltaEta**2 + deltaPhi**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6mkSW43ZTY7j"
   },
   "outputs": [],
   "source": [
    "def calcGroundCostMatrix_3D(xs, xt):\n",
    "  \"\"\"\n",
    "  Auxiliary function, assumes ground space is pT,eta,phi.\n",
    "  phi is 2pi modular which must be taken into account when computing the matrix of\n",
    "  pair-wise |x - y|^2 distances\n",
    "  \"\"\"\n",
    "  deltaPT      = xs[:,0,None] - xt[:,0]\n",
    "  deltaEta     = xs[:,1,None] - xt[:,1]\n",
    "  deltaPhi_raw = xs[:,2,None] - xt[:,2]\n",
    "  deltaPhi     = np.pi - np.abs(np.pi - np.abs(deltaPhi_raw))\n",
    "  return deltaPT**2 + deltaEta**2 + deltaPhi**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quKuyCqjN_4K"
   },
   "source": [
    "#### `calcOTDistance()`\n",
    "\n",
    "Also contains\n",
    "- `checkSCHEMES()`\n",
    "- `getMasses()`\n",
    "- `calcOTDistance_noZeroPadding()`\n",
    "- `calcOTDistance_unbalanced()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1m9QSH68XjcH"
   },
   "source": [
    "  NOTE: We're using the following references from the POT library ([here](https://pythonot.github.io/auto_examples/plot_OT_2D_samples.html#sphx-glr-auto-examples-plot-ot-2d-samples-py) and [here](https://pythonot.github.io/quickstart.html#solving-optimal-transport))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NZoPKQ3jODyd"
   },
   "outputs": [],
   "source": [
    "# def calcOTDistance(xEvents, yEvents, OTSCHEME, COSTSCHEME, kwargs={}):\n",
    "#   \"\"\"\n",
    "#   Solve the optimal transport problem and find the 2-Wasserstein distance\n",
    "#   for a set of source events (xEvents) and target events (yEvents) for a\n",
    "#   given ground cost function.\n",
    "\n",
    "#   Inputs:\n",
    "#         xEvents:  Array of sample of x-type events; shape (N, 19, 3)\n",
    "#         yEvents:  Array of sample of y-type events; shape (N, 19, 3)\n",
    "#        OTSCHEME:  Determines what scheme will be used to calculate the OT distance.\n",
    "#                   Note the exact meaning varies somewhat depending on the choice of COSTSCHEME.\n",
    "#                   It's a dictionary of 3 booleans cooresponding to whether the PT is normalized,\n",
    "#                   whether the OT calculation is balanced, and whether the zero padding should be\n",
    "#                   removed. Namely,\n",
    "#                   OTSCHEME['normPT']      ==True:  Means that the pT should be normalized;\n",
    "#                                          ==False:  Means that the pT should be unnormalized\n",
    "#                   OTSCHEME['balanced']    ==True:  Means that the OT calculation should be balanced;\n",
    "#                                          ==False:  Means that the OT calculation should be unbalanced\n",
    "#                   OTSCHEME['noZeroPad']   ==True:  Means that the zero padding should be removed;\n",
    "#                                          ==False:  Means that the zero padding should be kept\n",
    "#                   OTSCHEME['individualOT']==True:  Means that the OT calculation is done on each species separately;\n",
    "#                                          ==False:  Means that the OT calculation is done ignoring species type\n",
    "#      COSTSCHEME:  Determines what scheme will be used to calculate the ground cost matrix. Options are:\n",
    "#                   - 1DpT: Ground space is pT only\n",
    "#                   - 2D:   Ground space is 2D (eta,phi); note mass is pT\n",
    "#                   - 3D:   Ground space is 3D (pT,eta,phi); note mass is uniform\n",
    "\n",
    "#   Outputs\n",
    "#      CXY:  List of length N**2 the X-to-Y OT cost matrices, each of shape (nx, ny)\n",
    "#            nx(ny) = number of entries in xEvents(yEvents) <= 19\n",
    "#      wXY:  Array of the corresponding (squared) 2-Wasserstein distances\n",
    "#   \"\"\"\n",
    "\n",
    "#   #-- Sanity checks on inputs --#\n",
    "\n",
    "#   # Check schemes\n",
    "#   assert checkSCHEMES(OTSCHEME, COSTSCHEME)==True\n",
    "#   if OTSCHEME['balanced']==False:\n",
    "#     assert all([x in list(kwargs.keys()) for x in ['div', 'reg_m'] ])\n",
    "\n",
    "#   # Get number of signal and background events #! Make more general later to handle different number of x and y events\n",
    "#   assert(xEvents.shape[0] == yEvents.shape[0])\n",
    "#   N = xEvents.shape[0]\n",
    "\n",
    "#   #-- Preliminaries --#\n",
    "#   # Create objects for outputs\n",
    "#   CXY = []\n",
    "#   wXY = np.zeros(shape=(N,N))\n",
    "\n",
    "#   #-- Loop over pairs of events --#\n",
    "#   # We use itertools to make looping more efficient (i.e. do double for loops)\n",
    "#   dummyArr = np.arange(N)\n",
    "#   for (i,j) in itertools.product(dummyArr, dummyArr): #! Implement diagonal+upper-triangle restriction to save on computation time\n",
    "\n",
    "#     #-- Get source and target data points--#\n",
    "#     # Remove zero-padding if specified\n",
    "#     if OTSCHEME['noZeroPad']==True:\n",
    "#       sMask = ~np.all(xEvents[i, :, :] == 0., axis=1) # Mask to remove zero rows\n",
    "#       tMask = ~np.all(yEvents[j, :, :] == 0., axis=1)\n",
    "\n",
    "#       xs = xEvents[i, :, :][sMask] # \"source data points\"\n",
    "#       xt = yEvents[j, :, :][tMask] # \"target data points\"\n",
    "#     else:\n",
    "#       xs = xEvents[i, :, :] # \"source data points\"\n",
    "#       xt = yEvents[j, :, :] # \"target data points\"\n",
    "\n",
    "#     #-- Get masses --#\n",
    "#     a,b = getMasses(xs, xt, OTSCHEME, COSTSCHEME)\n",
    "\n",
    "#     #-- Normalize pT coordinate if specified --#\n",
    "#     #! Might be more efficient to do this before getMasses() but then will need to change getMasses()\n",
    "#     if OTSCHEME['normPT']==True:\n",
    "#       totPTs, totPTt = xs[:,0].sum(), xt[:,0].sum()\n",
    "#       xs[:,0], xt[:,0] = xs[:,0]/totPTs, xt[:,0]/totPTt\n",
    "\n",
    "#     #-- Get cost function and append to list --#\n",
    "#     cxy = calcGroundCostMatrix(xs, xt, COSTSCHEME)\n",
    "#     CXY.append(cxy)\n",
    "\n",
    "#     #-- Calculate the unbalanced Wasserstein distance --#\n",
    "#     if OTSCHEME['balanced']==False:\n",
    "#       wXY[i,j] = ot.unbalanced.mm_unbalanced2(a, b, cxy, reg_m=kwargs['reg_m'], div=kwargs['div'])\n",
    "#     else:\n",
    "#       wXY[i,j] = ot.emd2(a, b, cxy)\n",
    "\n",
    "#   return CXY, wXY.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "roJdpjPGRAv9"
   },
   "outputs": [],
   "source": [
    "def calcOTDistance(xEvents, yEvents, OTSCHEME, COSTSCHEME, kwargs={}, Matrix = False):\n",
    "  \"\"\"\n",
    "  Solve the optimal transport problem and find the 2-Wasserstein distance\n",
    "  for a set of source events (xEvents) and target events (yEvents) for a\n",
    "  given ground cost function.\n",
    "\n",
    "  Inputs:\n",
    "        xEvents:  Array of sample of x-type events; shape (N, 19, 3)\n",
    "        yEvents:  Array of sample of y-type events; shape (N, 19, 3)\n",
    "       OTSCHEME:  Determines what scheme will be used to calculate the OT distance.\n",
    "                  Note the exact meaning varies somewhat depending on the choice of COSTSCHEME.\n",
    "                  It's a dictionary of 3 booleans cooresponding to whether the PT is normalized,\n",
    "                  whether the OT calculation is balanced, and whether the zero padding should be\n",
    "                  removed. Namely,\n",
    "                  OTSCHEME['normPT']      ==True:  Means that the pT should be normalized;\n",
    "                                         ==False:  Means that the pT should be unnormalized\n",
    "                  OTSCHEME['balanced']    ==True:  Means that the OT calculation should be balanced;\n",
    "                                         ==False:  Means that the OT calculation should be unbalanced\n",
    "                  OTSCHEME['noZeroPad']   ==True:  Means that the zero padding should be removed;\n",
    "                                         ==False:  Means that the zero padding should be kept\n",
    "                  OTSCHEME['individualOT']==True:  Means that the OT calculation is done on each species separately;\n",
    "                                         ==False:  Means that the OT calculation is done ignoring species type\n",
    "     COSTSCHEME:  Determines what scheme will be used to calculate the ground cost matrix. Options are:\n",
    "                  - 1DpT: Ground space is pT only\n",
    "                  - 2D:   Ground space is 2D (eta,phi); note mass is pT\n",
    "                  - 3D:   Ground space is 3D (pT,eta,phi); note mass is uniform\n",
    "\n",
    "  Outputs\n",
    "     CXY:  List of length N**2 the X-to-Y OT cost matrices, each of shape (nx, ny)\n",
    "           nx(ny) = number of entries in xEvents(yEvents) <= 19\n",
    "     wXY:  Array of the corresponding (squared) 2-Wasserstein distances\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Sanity checks on inputs --#\n",
    "\n",
    "  # Check schemes\n",
    "  assert checkSCHEMES(OTSCHEME, COSTSCHEME)==True\n",
    "  if OTSCHEME['balanced']==False:\n",
    "    assert all([x in list(kwargs.keys()) for x in ['div', 'reg_m'] ])\n",
    "\n",
    "  # Get number of signal and background events #! Make more general later to handle different number of x and y events\n",
    "  assert(xEvents.shape[0] == yEvents.shape[0])\n",
    "  N = xEvents.shape[0]\n",
    "\n",
    "  #-- Preliminaries --#\n",
    "  # Create objects for outputs\n",
    "  # CXY = []\n",
    "  wXY = np.zeros(shape=(N,N))\n",
    "\n",
    "  #-- Loop over pairs of events --#\n",
    "  # We use itertools to make looping more efficient (i.e. do double for loops)\n",
    "  dummyArr = np.arange(N)\n",
    "  wXY_list = []\n",
    "  for (i, j) in tqdm(itertools.product(dummyArr, dummyArr), total=len(dummyArr)**2): #! Implement diagonal+upper-triangle restriction to save on computation time\n",
    "  # for (i, j) in itertools.product(dummyArr, dummyArr):\n",
    "    #-- Get source and target data points--#\n",
    "    # Remove zero-padding if specified\n",
    "    if OTSCHEME['noZeroPad']==True:\n",
    "      sMask = ~np.all(xEvents[i, :, :] == 0., axis=1) # Mask to remove zero rows\n",
    "      tMask = ~np.all(yEvents[j, :, :] == 0., axis=1)\n",
    "\n",
    "      xs = xEvents[i, :, :][sMask] # \"source data points\"\n",
    "      xt = yEvents[j, :, :][tMask] # \"target data points\"\n",
    "    else:\n",
    "      xs = xEvents[i, :, :] # \"source data points\"\n",
    "      xt = yEvents[j, :, :] # \"target data points\"\n",
    "\n",
    "    #-- Get masses --#\n",
    "    a,b = getMasses(xs, xt, OTSCHEME, COSTSCHEME)\n",
    "\n",
    "    #-- Normalize pT coordinate if specified --#\n",
    "    #! Might be more efficient to do this before getMasses() but then will need to change getMasses()\n",
    "    if OTSCHEME['normPT']==True:\n",
    "      totPTs, totPTt = xs[:,0].sum(), xt[:,0].sum()\n",
    "      xs[:,0], xt[:,0] = xs[:,0]/totPTs, xt[:,0]/totPTt\n",
    "\n",
    "    #-- Get cost function and append to list --#\n",
    "    cxy = calcGroundCostMatrix(xs, xt, COSTSCHEME)\n",
    "    # CXY.append(cxy)\n",
    "\n",
    "    #-- Calculate the unbalanced Wasserstein distance --#\n",
    "    if OTSCHEME['balanced']==False:\n",
    "      if j >= i:\n",
    "        wXY[i,j] = ot.unbalanced.mm_unbalanced2(a, b, cxy, reg_m=kwargs['reg_m'], div=kwargs['div'])\n",
    "        wXY_list.append(wXY[i,j])\n",
    "      else:\n",
    "        wXY[i,j] = wXY[j,i]\n",
    "    else:\n",
    "      if j >= i:\n",
    "        wXY[i,j] = ot.emd2(a, b, cxy)\n",
    "        wXY_list.append(wXY[i,j])\n",
    "      else:\n",
    "        wXY[i,j] = wXY[j,i]\n",
    "\n",
    "  if Matrix == True:\n",
    "    return wXY\n",
    "\n",
    "  else:\n",
    "    return np.asarray(wXY_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcOTDistance_non_square(xEvents, yEvents, OTSCHEME, COSTSCHEME, kwargs={}, Matrix = False):\n",
    "  \"\"\"\n",
    "  Solve the optimal transport problem and find the 2-Wasserstein distance\n",
    "  for a set of source events (xEvents) and target events (yEvents) for a\n",
    "  given ground cost function.\n",
    "\n",
    "  Inputs:\n",
    "        xEvents:  Array of sample of x-type events; shape (N, 19, 3)\n",
    "        yEvents:  Array of sample of y-type events; shape (N, 19, 3)\n",
    "       OTSCHEME:  Determines what scheme will be used to calculate the OT distance.\n",
    "                  Note the exact meaning varies somewhat depending on the choice of COSTSCHEME.\n",
    "                  It's a dictionary of 3 booleans cooresponding to whether the PT is normalized,\n",
    "                  whether the OT calculation is balanced, and whether the zero padding should be\n",
    "                  removed. Namely,\n",
    "                  OTSCHEME['normPT']      ==True:  Means that the pT should be normalized;\n",
    "                                         ==False:  Means that the pT should be unnormalized\n",
    "                  OTSCHEME['balanced']    ==True:  Means that the OT calculation should be balanced;\n",
    "                                         ==False:  Means that the OT calculation should be unbalanced\n",
    "                  OTSCHEME['noZeroPad']   ==True:  Means that the zero padding should be removed;\n",
    "                                         ==False:  Means that the zero padding should be kept\n",
    "                  OTSCHEME['individualOT']==True:  Means that the OT calculation is done on each species separately;\n",
    "                                         ==False:  Means that the OT calculation is done ignoring species type\n",
    "     COSTSCHEME:  Determines what scheme will be used to calculate the ground cost matrix. Options are:\n",
    "                  - 1DpT: Ground space is pT only\n",
    "                  - 2D:   Ground space is 2D (eta,phi); note mass is pT\n",
    "                  - 3D:   Ground space is 3D (pT,eta,phi); note mass is uniform\n",
    "\n",
    "  Outputs\n",
    "     \n",
    "     wXY:  Matrix of the corresponding (squared) 2-Wasserstein distances, or list for default\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Sanity checks on inputs --#\n",
    "\n",
    "  # Check schemes\n",
    "  assert checkSCHEMES(OTSCHEME, COSTSCHEME)==True\n",
    "  if OTSCHEME['balanced']==False:\n",
    "    assert all([x in list(kwargs.keys()) for x in ['div', 'reg_m'] ])\n",
    "\n",
    "  N = xEvents.shape[0]\n",
    "  M = yEvents.shape[0]\n",
    "  #-- Preliminaries --#\n",
    "  # Create objects for outputs\n",
    "  # CXY = []\n",
    "  wXY = np.zeros(shape=(N,M))\n",
    "\n",
    "  #-- Loop over pairs of events --#\n",
    "  # We use itertools to make looping more efficient (i.e. do double for loops)\n",
    "  dummyArr_1 = np.arange(N)\n",
    "  dummyArr_2 = np.arange(M)\n",
    "  wXY_list = []\n",
    "  # for (i, j) in tqdm(itertools.product(dummyArr_1, dummyArr_2), total=len(dummyArr_1)*len(dummyArr_2)): #! Implement diagonal+upper-triangle restriction to save on computation time\n",
    "  for (i, j) in itertools.product(dummyArr_1, dummyArr_2):\n",
    "    #-- Get source and target data points--#\n",
    "    # Remove zero-padding if specified\n",
    "    if OTSCHEME['noZeroPad']==True:\n",
    "      sMask = ~np.all(xEvents[i, :, :] == 0., axis=1) # Mask to remove zero rows\n",
    "      tMask = ~np.all(yEvents[j, :, :] == 0., axis=1)\n",
    "\n",
    "      xs = xEvents[i, :, :][sMask] # \"source data points\"\n",
    "      xt = yEvents[j, :, :][tMask] # \"target data points\"\n",
    "    else:\n",
    "      xs = xEvents[i, :, :] # \"source data points\"\n",
    "      xt = yEvents[j, :, :] # \"target data points\"\n",
    "\n",
    "    #-- Get masses --#\n",
    "    a,b = getMasses(xs, xt, OTSCHEME, COSTSCHEME)\n",
    "\n",
    "    #-- Normalize pT coordinate if specified --#\n",
    "    #! Might be more efficient to do this before getMasses() but then will need to change getMasses()\n",
    "    if OTSCHEME['normPT']==True:\n",
    "      totPTs, totPTt = xs[:,0].sum(), xt[:,0].sum()\n",
    "      xs[:,0], xt[:,0] = xs[:,0]/totPTs, xt[:,0]/totPTt\n",
    "\n",
    "    #-- Get cost function and append to list --#\n",
    "    cxy = calcGroundCostMatrix(xs, xt, COSTSCHEME)\n",
    "    # CXY.append(cxy)\n",
    "\n",
    "    #-- Calculate the unbalanced Wasserstein distance --#\n",
    "    if OTSCHEME['balanced']==False:\n",
    "      wXY[i,j] = ot.unbalanced.mm_unbalanced2(a, b, cxy, reg_m=kwargs['reg_m'], div=kwargs['div'])\n",
    "      wXY_list.append(wXY[i,j])\n",
    "    else:\n",
    "      wXY[i,j] = ot.emd2(a, b, cxy)\n",
    "      wXY_list.append(wXY[i,j])\n",
    "\n",
    "  if Matrix == True:\n",
    "    return wXY\n",
    "\n",
    "  else:\n",
    "    return np.asarray(wXY_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_OT_non_square(event_set1, event_set2, OTSCHEME, COSTSCHEME, kwargs, num_cores = 8):\n",
    "    num_events = len(event_set1)\n",
    "    assert num_events%num_cores == 0, 'Number of events must be divisible by number of cores'\n",
    "    num_per_core = num_events//num_cores\n",
    "    with cf.ProcessPoolExecutor() as executor:\n",
    "    \n",
    "        futures = [executor.submit(calcOTDistance_non_square, event_set1[num_per_core*i:num_per_core*(i+1)], event_set2, OTSCHEME, COSTSCHEME, kwargs=kwargs, Matrix = True) for i in range(num_cores)]\n",
    "    \n",
    "    results = [f.result() for f in futures]\n",
    "    \n",
    "    distance_matrix = np.vstack(results)\n",
    "    \n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_to_ensemble_dist(wXY, EVENT_TO_ENSEMBLE_TYPE, AXIS=0):\n",
    "    \"\"\"\n",
    "    Calculate the event to ensemble distance.\n",
    "    wXY should be an NxN matrix where wXY[i,j] is the OT distance between X[i] and Y[j]\n",
    "    AXIS=0 assumes that X events are the reference population (i.e. ensemble)\n",
    "    \"\"\"\n",
    "    if EVENT_TO_ENSEMBLE_TYPE=='MAX':\n",
    "        return np.max(wXY, axis=AXIS)\n",
    "    elif EVENT_TO_ENSEMBLE_TYPE=='MIN':\n",
    "        return np.min(wXY, axis=AXIS)\n",
    "    elif EVENT_TO_ENSEMBLE_TYPE=='MEAN':\n",
    "        return np.mean(wXY, axis=AXIS)\n",
    "    else:\n",
    "        print(\"ERROR: Invalid EVENT_TO_ENSEMBLE_TYPE \",EVENT_TO_ENSEMBLE_TYPE)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNsEvX-Siv9x"
   },
   "source": [
    "##### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PldekATelQZJ"
   },
   "outputs": [],
   "source": [
    "def checkSCHEMES(OTSCHEME, COSTSCHEME):\n",
    "  \"\"\"\n",
    "  Auxiliary function to make calcOTDistance() a bit tidier while still checking that the schemes make sense\n",
    "\n",
    "  See calcOTDistance for definition of OTSCHEME, COSTSCHEME\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Check that SCHEMES contain valid entries --#\n",
    "  assert (COSTSCHEME in ['1DpT','2D', '3D']), \"Error: Invalid COSTSCHEME\"\n",
    "  for key in OTSCHEME.keys():\n",
    "    assert(OTSCHEME[key] in [True, False]), \"Error: Invalid OTSCHEME\"\n",
    "\n",
    "\n",
    "  #-- Check that SCHEME combinations make sense --#\n",
    "\n",
    "  if COSTSCHEME == '1DpT':\n",
    "\n",
    "    # pT assumed to be unnormalized\n",
    "    assert (OTSCHEME['normPT']==False), \"Error: Invalid OTSCHEME['normPT'] for COSTSCHEME==%s\"%(COSTSCHEME)\n",
    "\n",
    "    # either balanced or unbalanced is fine\n",
    "    # => nothing to check\n",
    "\n",
    "    # if doing balanced then either removing or keeping zero padding is fine => nothing to check;\n",
    "    # if doing unbalanced then zero padding should be removed\n",
    "    if OTSCHEME['balanced']==False:\n",
    "      assert (OTSCHEME['noZeroPad']==True), \"Error: Invalid OTSCHEME['noZeroPad'] for COSTSCHEME==%s\"%(COSTSCHEME)\n",
    "\n",
    "    # check that we're not doing individual OT\n",
    "    assert (OTSCHEME['individualOT']==False), \"Error: Invalid OTSCHEME['individualOT'] for COSTSCHEME==%s\"%(COSTSCHEME)\n",
    "\n",
    "  elif COSTSCHEME == '2D':\n",
    "\n",
    "    # either normalized or unnormalized pT is fine\n",
    "    # => nothing to check\n",
    "\n",
    "    # if pT is unnormalized we must be doing unbalanced\n",
    "    # if pT is normalized we assume we're doing balanced\n",
    "    if OTSCHEME['normPT']==False:\n",
    "      assert (OTSCHEME['balanced']==False), \"Error: Invalid OTSCHEME['balanced'] for COSTSCHEME==%s\"%(COSTSCHEME)\n",
    "    elif OTSCHEME['normPT']==True:\n",
    "      assert (OTSCHEME['balanced']==True), \"Error: Invalid OTSCHEME['balanced'] for COSTSCHEME==%s\"%(COSTSCHEME)\n",
    "\n",
    "    # check that we're not doing individual OT\n",
    "    assert (OTSCHEME['individualOT']==False), \"Error: Invalid OTSCHEME['individualOT'] for COSTSCHEME==%s\"%(COSTSCHEME)\n",
    "\n",
    "  elif COSTSCHEME == '3D':\n",
    "\n",
    "    # either normalized or unnormalized pT is fine\n",
    "    # => nothing to check\n",
    "\n",
    "    # either balanced or unbalanced is fine\n",
    "    # => nothing to check\n",
    "\n",
    "    # either removing or keeping zero padding is fine\n",
    "    # => nothing to check\n",
    "\n",
    "    # if we're doing individual species we want balanced OT with unnormalized pT and zero padding intact\n",
    "    if OTSCHEME['individualOT'] == True:\n",
    "      assert (OTSCHEME['balanced']==True),   \"Error: Invalid OTSCHEME['balanced'] for individualOT and COSTSCHEME==%s\"%(COSTSCHEME)\n",
    "      assert (OTSCHEME['normPT']==False),    \"Error: Invalid OTSCHEME['normPT'] for individualOT and COSTSCHEME==%s\"%(COSTSCHEME)\n",
    "      assert (OTSCHEME['noZeroPad']==False), \"Error: Invalid OTSCHEME['noZeroPad'] for individualOT and COSTSCHEME==%s\"%(COSTSCHEME)\n",
    "\n",
    "\n",
    "  # If all assert statements passed without issue then return True\n",
    "  return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "14AxAkkPxMlN"
   },
   "outputs": [],
   "source": [
    "def getMasses(xs, xt, OTSCHEME, COSTSCHEME):\n",
    "  \"\"\"\n",
    "  Auxiliary function to get probability masses based on OTSCHEME and COSTSCHEME.\n",
    "  There are 5 different options.\n",
    "  \"\"\"\n",
    "  #-- Option 1:  m_i = 1/19 --#\n",
    "  # There are 3 combinations that give this\n",
    "  # They assume 1D or 3D, balanced, and zero-padded\n",
    "  if (COSTSCHEME != '2D') and (OTSCHEME['balanced']==True) and (OTSCHEME['noZeroPad']==False) and (OTSCHEME['individualOT']==False):\n",
    "    a = np.ones((19,)) / 19\n",
    "    b = a\n",
    "\n",
    "  #-- Option 2: m_i = 1, 1/4, or 1/10 depending on individual species type --#\n",
    "  elif (COSTSCHEME != '2D') and (OTSCHEME['balanced']==True) and (OTSCHEME['noZeroPad']==False) and (OTSCHEME['individualOT']==True):\n",
    "    nx, ny = xs.shape[0], xt.shape[0]\n",
    "    a = np.ones((nx,)) / nx\n",
    "    b = np.ones((ny,)) / ny\n",
    "\n",
    "  #-- Option 3: m_i = 1/N, N=number of particles in the event --#\n",
    "  # There are 3 combinations that give this\n",
    "  # They assume 1D or 3D, balanced, and zero-padding removed\n",
    "  elif (COSTSCHEME != '2D') and (OTSCHEME['balanced']==True) and (OTSCHEME['noZeroPad']==True):\n",
    "    nx, ny = xs.shape[0], xt.shape[0]\n",
    "    a = np.ones((nx,)) / nx\n",
    "    b = np.ones((ny,)) / ny\n",
    "\n",
    "  #-- Option 4: m_i = pT --#\n",
    "  # There is only 1 combination that gives this\n",
    "  elif (COSTSCHEME == '2D') and (OTSCHEME['normPT']==False):\n",
    "    a = xs[:,0]\n",
    "    b = xt[:,0]\n",
    "\n",
    "  #-- Option 5: m_i = pT/sum(pT) --#\n",
    "  # There is only 1 combination that gives this\n",
    "  elif (COSTSCHEME == '2D') and (OTSCHEME['normPT']==True):\n",
    "    totalpT_xs = np.sum(xs[:,0]) # Total pT in each x-event\n",
    "    totalpT_xt = np.sum(xt[:,0]) # Total pT in each y-event\n",
    "\n",
    "    a = np.ascontiguousarray(xs[:,0]/totalpT_xs) # POT error will result if not C-contiguous\n",
    "    b = np.ascontiguousarray(xt[:,0]/totalpT_xt)\n",
    "\n",
    "    # Assuming balanced OT, both total masses should be the same (up to some precision)\n",
    "    # Using same precision considerations as POT library which is the default for np.testing.assert_almost_equal() (decimal=7)\n",
    "    np.testing.assert_almost_equal(a.sum(0), b.sum(0,keepdims=True), err_msg='a and b vector must have the same sum')\n",
    "\n",
    "  #-- Option 6: m_i = 1 --#\n",
    "  else:\n",
    "    nx, ny = xs.shape[0], xt.shape[0]\n",
    "    a = np.ones((nx,))\n",
    "    b = np.ones((ny,))\n",
    "\n",
    "  return a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1UbpU7RPUkY"
   },
   "source": [
    "##### `calcIndividualOTScores()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vsWBfMJWOiog"
   },
   "outputs": [],
   "source": [
    "def calcIndividualOTScores(trimmedDataDict, sigAliasList, OTSCHEME, COSTSCHEME, kwargs={}, speciesList=['MET', 'e', 'mu', 'jet']):\n",
    "  \"\"\"\n",
    "  Calculate individual OT scores and store them in a score dictionary.\n",
    "\n",
    "  Inputs:\n",
    "    trimmedDataDict:  Dictionary of data trimmed to size (N, 19, 3); contains\n",
    "                      two samples of background data ('bkgEvents1' and 'bkgEvents2')\n",
    "                      and one sample of signal data for each signal type ('sig_A',\n",
    "                      'sig_h0', 'sig_hch', 'sig_LQ')\n",
    "    sigAliasList:     List of signal type aliases; i.e. ['sig_A', 'sig_h0', 'sig_hch', 'sig_LQ']\n",
    "    speciesList:      List of species; default ['MET', 'e', 'mu', 'jet']\n",
    "\n",
    "  Outputs:\n",
    "    scoreDict: Dictionary of scores for OT on each particle species\n",
    "  \"\"\"\n",
    "  scoreDict = {}\n",
    "\n",
    "  #-- Loop over particle species\n",
    "  for species in speciesList:\n",
    "    scoreDict[species] = {}\n",
    "\n",
    "    #-- Set background data according to species type --#\n",
    "    if species == 'MET':\n",
    "      B1_data = trimmedDataDict['bkgEvents1'][:, 0, :].reshape(-1,1,3)\n",
    "      B2_data = trimmedDataDict['bkgEvents2'][:, 0, :].reshape(-1,1,3)\n",
    "    elif species == 'e':\n",
    "      B1_data = trimmedDataDict['bkgEvents1'][:, 1:5, :]\n",
    "      B2_data = trimmedDataDict['bkgEvents2'][:, 1:5, :]\n",
    "    elif species == 'mu':\n",
    "      B1_data = trimmedDataDict['bkgEvents1'][:, 5:9, :]\n",
    "      B2_data = trimmedDataDict['bkgEvents2'][:, 5:9, :]\n",
    "    elif species == 'jet':\n",
    "      B1_data = trimmedDataDict['bkgEvents1'][:, 9:, :]\n",
    "      B2_data = trimmedDataDict['bkgEvents2'][:, 9:, :]\n",
    "\n",
    "    #-- Calculate OT distance for background-to-background case --#\n",
    "    _, scoreDict[species]['wBB'] = calcOTDistance(B1_data, B2_data, OTSCHEME=OTSCHEME, COSTSCHEME=COSTSCHEME, kwargs=kwargs)\n",
    "\n",
    "    #-- Loop over signal cases to calculate OT distance in background-to-signal case --#\n",
    "    for alias in sigAliasList:\n",
    "\n",
    "      #-- Set signal data according to species type --#\n",
    "      if species == 'MET':\n",
    "        S_data = trimmedDataDict[alias][:, 0, :].reshape(-1,1,3)\n",
    "      elif species == 'e':\n",
    "        S_data = trimmedDataDict[alias][:, 1:5, :]\n",
    "      elif species == 'mu':\n",
    "        S_data = trimmedDataDict[alias][:, 5:9, :]\n",
    "      elif species == 'jet':\n",
    "        S_data = trimmedDataDict[alias][:, 9:, :]\n",
    "\n",
    "      #-- Calculate OT distance for background-to-signal case --#\n",
    "      name_w = 'wBS_'+alias\n",
    "      _, scoreDict[species][name_w] = calcOTDistance(B1_data, S_data, OTSCHEME=OTSCHEME, COSTSCHEME=COSTSCHEME, kwargs=kwargs)\n",
    "\n",
    "  return scoreDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URikDA8PRCr2"
   },
   "source": [
    "# Data handling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lmx6vvZlOv52"
   },
   "source": [
    "##### `randomDataSample()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "m4-zA4qQOW_C"
   },
   "outputs": [],
   "source": [
    "def randomDataSample(data, nEvents, random_state):\n",
    "  \"\"\"\n",
    "  Generate a random sample of data by generating a 1D array of nEvents uniform\n",
    "  random integers and returning the events corresponding to these integers.\n",
    "\n",
    "  Inputs:\n",
    "    data:          Total data array of shape (nTotal, 19, 3)\n",
    "    nEvents:       Number of events to sample\n",
    "    random_state:  The generator to use to generate the samples (for reproducibility)\n",
    "\n",
    "  Outputs:\n",
    "    Selected events; shape (nEvents, 19, 3)\n",
    "  \"\"\"\n",
    "  #! Pretty slow in practice (not sure why), make it faster later\n",
    "\n",
    "  nTotal = data.shape[0]\n",
    "  randomIntArray = random_state.integers(0,nTotal,nEvents)\n",
    "\n",
    "  return data[randomIntArray, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `calcROCmetrics()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcROCmetrics(scoreBkg, scoreSigList, SIreg=0.0001, INTERPOLATE=True):\n",
    "    \"\"\"\n",
    "    Calculate 4 metrics related to ROC curve components:\n",
    "        - AUC\n",
    "        - Background efficiency (aka FPR or eps_B), Signal efficiency (aka TPR or eps_S)\n",
    "        - Significance Improvement (SI) defined as eps_S/sqrt(eps_B + SIreg) <=> TPR/sqrt(FPR + SIreg)\n",
    "          where SIreg is a regulator for statistical fluctuations at low efficiency; SIreg=0.01% by default\n",
    "          Reference: https://arxiv.org/pdf/2001.05001.pdf\n",
    "        - Inverse Background efficiency (aka FPR^{-1} or eps_B^{-1}); division by zero is masked\n",
    "\n",
    "    Inputs:\n",
    "      scoreBkg:      Anomaly score values for N background events; shape (N,)\n",
    "      scoreSigList:  List of anomaly score values for each signal type case; Length=nCases\n",
    "                    scoreSigList[i] is the anomaly score for M signal events of the ith signal type case; shape (M,)\n",
    "      SIreg:         Regulator to prevent division by zero when calculating SI metric; default 0.01%\n",
    "      INTERPOLATE:   Whether to interpolate to a standard array of TPR values\n",
    "\n",
    "    Outputs:\n",
    "      aucList:       List of AUC scores for each background to signal type pairing; Length=nCases\n",
    "      fprList:       List of FPR arrays for each background to signal type pairing; Length=nCases\n",
    "                    fprList[i] is an array of shape (Q,) with Q>2\n",
    "      tprList:       List of TPR arrays for each background to signal type pairing; Length=nCases\n",
    "                    tprList[i] is an array of shape (Q,) with Q>2\n",
    "      SIList:        List of SI arrays for each background to signal type pairing; Length=nCases\n",
    "                    SIList[i] is an array of shape (Q,) with Q>2\n",
    "      fprInvList:    List of inverse FPR arrays for each background to signal type pairing; Length=nCases\n",
    "                    fprInvList[i] is a masked array of shape (Q,) with Q>2 with division by zero cases masked\n",
    "      F1List:        List of F1 score arrays for each background to signal type pairing; Length=nCases\n",
    "                    F1List[i] is an array of shape (Q,) with Q>2\n",
    "    \"\"\"\n",
    "\n",
    "    #-- Preliminaries --#\n",
    "    nCases    = len(scoreSigList) # Number of signal cases\n",
    "    aucList, fprList, tprList, SIList, fprInvList, F1List = [], [], [], [], [], [] # Create lists to store results\n",
    "\n",
    "    #-- Loop over signal cases --#\n",
    "    for i in range(nCases):\n",
    "      scoreSig = scoreSigList[i]\n",
    "\n",
    "      #-- Calculate AUC (and, internally, label and score inputs for sklearn's function) --#\n",
    "      auc, labels, scores = calcAUC(scoreBkg, scoreSig)\n",
    "      aucList.append(auc)\n",
    "\n",
    "      #-- Calculate other ROC curve metrics --#\n",
    "      fpr_raw, tpr_raw, _ = metrics.roc_curve(labels, scores)\n",
    "\n",
    "      if INTERPOLATE:\n",
    "        #https://stats.stackexchange.com/questions/186337/average-roc-for-repeated-10-fold-cross-validation-with-probability-estimates\n",
    "        base_tpr = np.linspace(0, 1, 101) # 0.00, 0.01, ..., 1.0\n",
    "        tpr = base_tpr\n",
    "        fpr = np.interp(base_tpr, tpr_raw, fpr_raw)\n",
    "      else:\n",
    "        fpr = fpr_raw\n",
    "        tpr = tpr_raw\n",
    "\n",
    "      fprList.append(fpr)\n",
    "      tprList.append(tpr)\n",
    "\n",
    "      #-- Calculate SI metric --#\n",
    "      # Def: eps_S/sqrt(eps_B + SIreg) <=> TPR/sqrt(FPR + SIreg)\n",
    "      fpr_sqrt = np.sqrt(fpr + SIreg)\n",
    "      SI = tpr/fpr_sqrt\n",
    "      SIList.append(SI)\n",
    "\n",
    "      #-- Calculate inverse FPR metric --#\n",
    "      #! Should we also use regulator here? Is this typical?\n",
    "      fpr_masked = ma.masked_where(fpr==0., fpr) # Get rid of possibility of dividing by zero\n",
    "      fprInv = 1./fpr_masked\n",
    "      fprInvList.append(fprInv)\n",
    "\n",
    "      #-- Calculate F1 score metric --#\n",
    "      # Recall FNR := 1 - TPR\n",
    "      # Def of F1: (2*TPR)/(2*TPR + FPR + FNR) = (2*TPR)/(2*TPR + FPR + 1 - TPR) = (2*TPR)/(TPR + FPR + 1)\n",
    "      F1 = (2*tpr)/(tpr + fpr + 1)\n",
    "      F1List.append(F1)\n",
    "\n",
    "    return aucList, fprList, tprList, SIList, fprInvList, F1List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUqniKxLPC0G"
   },
   "source": [
    "##### `calcAUC()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BoWismZgOZ5I"
   },
   "outputs": [],
   "source": [
    "def calcAUC(scoreBkg, scoreSig):\n",
    "  \"\"\"\n",
    "  Given the anomaly scores for background and signal events, calculate the AUC.\n",
    "\n",
    "  Inputs:\n",
    "    scoreBkg:   Anomaly score values for N background events; shape (N,)\n",
    "    scoreSig:   Anomaly score values for M signal events; shape (M,)\n",
    "\n",
    "  Outputs:\n",
    "    auc:        Area Under the Curve (AUC) value; float\n",
    "    labels:     Numeric background/signal labels; 0 for background, 1 for signal\n",
    "                (necessary for ROC and AUC calculations); shape (N+M,)\n",
    "    scores:     Concatenated anomaly scores from background and signal events;\n",
    "                (necessary for ROC and AUC calculations); shape (N+M,)\n",
    "\n",
    "  NOTE: Using the sklearn.metrics.roc_auc_score() function\n",
    "  https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "  \"\"\"\n",
    "\n",
    "  labelsB = np.repeat(0, scoreBkg.shape[0]) # Background labels\n",
    "  labelsS = np.repeat(1, scoreSig.shape[0]) # Signal labels\n",
    "  labels  = np.concatenate((labelsB, labelsS))\n",
    "\n",
    "  scores  =  np.concatenate((scoreBkg, scoreSig))\n",
    "\n",
    "  auc = metrics.roc_auc_score(labels, scores)\n",
    "\n",
    "  return auc, labels, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stH-CGFTPQcM"
   },
   "source": [
    "##### `indxOfCertainTPR()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9HZb_tbbOf0t"
   },
   "outputs": [],
   "source": [
    "def indxOfCertainTPR(tprList, TPRval = 0.3):\n",
    "  \"\"\"\n",
    "  For each TPR array in tprList, get the index corresponding to the TPR value\n",
    "  which is closest to TPRval. This can be used to examine the other metrics at\n",
    "  a certain TPR (signal efficiency, \\eps_S) value.\n",
    "\n",
    "  Inputs:\n",
    "    tprList:   List of TPR arrays for each background to signal type pairing; Length=number of signal cases\n",
    "               tprList[i] is an array of shape (Q,) with Q>2\n",
    "    TPRval:    Fixed reference TPR value; default is TPR = \\eps_S = 30%\n",
    "\n",
    "  Outputs:\n",
    "    indxList:  List of indices corresponding to TPR ~= TPRval; length = number of signal cases\n",
    "  \"\"\"\n",
    "  indxList = []\n",
    "  nCases = len(tprList) # Number of signal cases\n",
    "\n",
    "  for i in range(nCases):\n",
    "    tprArr = tprList[i]\n",
    "    difference_array = np.absolute(tprArr-TPRval)\n",
    "    indx = difference_array.argmin()\n",
    "    indxList.append(indx)\n",
    "\n",
    "  return indxList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `getRepeatAvStd()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRepeatAvStd(scoreDict, sigAliasList=['sig_A', 'sig_h0', 'sig_hch', 'sig_LQ'], NREPEAT=5):\n",
    "    \"\"\"\n",
    "    Calculates average and standard deviation over repeats for the various ROC metrics: auc, fpr, SI, fprInv, F1.\n",
    "    For auc, the av and std are each a single number. Whereas, for fpr, SI, fprInv, F1 the av and std will each be arrays of the same respective size.\n",
    "\n",
    "    Inputs:\n",
    "        scoreDict:  Dictionary containing ROC metrics (auc, fpr, SI, fprInv, F1) for all signal cases. There are NREPEAT copies.\n",
    "                    Structure is assumed to be the following:\n",
    "                        scoreDict['repeat0']\n",
    "                                            ['ROC_metric_%s']%sigAliasList[0]\n",
    "                                                            ['auc']    # Shape = (NREPEAT,)\n",
    "                                                            ['fpr']    # Shape = (NREPEAT,n_Thresholds)\n",
    "                                                            ['SI']     # Shape = (NREPEAT,n_Thresholds)\n",
    "                                                            ['fprInv'] # Shape = (NREPEAT,n_Thresholds)\n",
    "                                                            ['F1']     # Shape = (NREPEAT,n_Thresholds)\n",
    "                                            ...\n",
    "                                            ['ROC_metric_%s']%sigAliasList[3]\n",
    "                        scoreDict['repeat1']\n",
    "                        ...\n",
    "                        scoreDict['repeat%s'%NREPEAT]\n",
    "\n",
    "        sigAliasList:  List of signal type alias\n",
    "            NREPEAT:  Number of repeated test sample sets.\n",
    "\n",
    "    NOTE: Assumes that calcROCmetrics() was calculated with INTERPOLATE=True => TPR is fixed to baseTPR.\n",
    "            This means n_Thresholds=101, corresponding to using baseTPR = np.linspace(0,1,101).\n",
    "\n",
    "    Outputs:\n",
    "        N/a, updates scoreDict with values under key 'avStdQuantities' for each signal type. For example,\n",
    "            scoreDict['avStdQuantities']['sig_A']['auc']['mean']\n",
    "                                                        ['std']\n",
    "    \"\"\"\n",
    "\n",
    "    REPEATLIST = ['repeat%d'%i for i in range(NREPEAT)]\n",
    "    scoreDict['avStdQuantities'] = {}\n",
    "\n",
    "    # Loop over signal types\n",
    "    for alias in sigAliasList:\n",
    "        print(\"Analyzing signal type = %s \"%alias)\n",
    "        name = 'ROC_metric_%s'%(alias)\n",
    "        scoreDict['avStdQuantities'][alias]                   = {}\n",
    "\n",
    "        # Get average and std of desired quantities\n",
    "        for quantity in ['auc', 'fpr', 'SI', 'fprInv', 'F1']:\n",
    "\n",
    "            qArr = np.array([scoreDict[key][name][quantity] for key in REPEATLIST ])\n",
    "            scoreDict['avStdQuantities'][alias][quantity]         = {}\n",
    "            scoreDict['avStdQuantities'][alias][quantity]['mean'] = qArr.mean(axis=0)\n",
    "            scoreDict['avStdQuantities'][alias][quantity]['std']  = qArr.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7-3CDlKPgTV"
   },
   "source": [
    "##### `calcWeightedComboOTscores()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qIV2ogm1OkwR"
   },
   "outputs": [],
   "source": [
    "def calcWeightedComboOTscores(scoreDict, wList=[1., 1., 1., 1.]):\n",
    "  \"\"\"\n",
    "  calculate a combination of individual species OT scores for each subkey case\n",
    "\n",
    "  Inputs:\n",
    "    scoreDict:  Dictionary of scores for OT on each particle species; e.g. scoreDict['MET']['wBB']\n",
    "    wList:      How much to weight 'MET', 'e', 'mu', 'jet' information, respectively, in the sum;\n",
    "                default equal weighting wList=[1., 1., 1., 1.]\n",
    "  Outputs:\n",
    "    Updated scoreDict\n",
    "  \"\"\"\n",
    "  #-- Calculate and store combination (sum) --#\n",
    "  scoreDict['combo'] = {}\n",
    "  for subkey in scoreDict['MET'].keys():\n",
    "    nameCombo = 'combo_'+str(subkey)\n",
    "    scoreDict['combo'][nameCombo]  = wList[0]*scoreDict['MET'][subkey] + wList[1]*scoreDict['e'][subkey] + wList[2]*scoreDict['mu'][subkey] + wList[3]*scoreDict['jet'][subkey]\n",
    "\n",
    "  return scoreDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDRscCjwPkb7"
   },
   "source": [
    "##### `getFractionsOfMax()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GX_VJScoPqg3"
   },
   "outputs": [],
   "source": [
    "def getFractionsOfMax(indxs, val):\n",
    "  \"\"\"\n",
    "  Calculates the fraction of indxs entries that equal val\n",
    "  \"\"\"\n",
    "\n",
    "  indxs_masked = ma.masked_where(indxs==val, indxs)\n",
    "  total        = indxs.shape[0]\n",
    "  fraction     = float(np.sum(indxs_masked.mask))/ float(total)\n",
    "\n",
    "  return fraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNSBamdZPswD"
   },
   "source": [
    "##### `maxIndividualOTScore()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dubD4k-tOnEP"
   },
   "outputs": [],
   "source": [
    "def maxIndividualOTScore(scoreDict, alias):\n",
    "  \"\"\"\n",
    "  Calculates which individual OT score is the largest for each event in signal type alias\n",
    "  \"\"\"\n",
    "\n",
    "  # Get individual OT scores from dictionary\n",
    "  metArr = scoreDict['MET'][alias].reshape(-1, 1)\n",
    "  eArr   = scoreDict['e'][alias].reshape(-1, 1)\n",
    "  muArr  = scoreDict['mu'][alias].reshape(-1, 1)\n",
    "  jetArr = scoreDict['jet'][alias].reshape(-1, 1)\n",
    "\n",
    "  comboArr = np.concatenate((metArr, eArr, muArr, jetArr), axis=1)\n",
    "\n",
    "  # Get index of max individual OT score for each event\n",
    "  # 0=met, 1=e, 2=mu, 3=jet\n",
    "  indxs  = np.argmax(comboArr, axis=1)\n",
    "  maxArr = np.max(comboArr, axis=1)\n",
    "\n",
    "  # Print fractions\n",
    "  print(\"Signal Type = \", alias)\n",
    "  print(\"Fraction of times that each individual OT score was the maximum for a given event:\")\n",
    "  print(\"   MET: %s \"%str(getFractionsOfMax(indxs, 0)*100))\n",
    "  print(\"     e: %s \"%str(getFractionsOfMax(indxs, 1)*100))\n",
    "  print(\"    mu: %s \"%str(getFractionsOfMax(indxs, 2)*100))\n",
    "  print(\"   jet: %s \"%str(getFractionsOfMax(indxs, 3)*100))\n",
    "\n",
    "  return indxs, maxArr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH88oRz6PzHo"
   },
   "source": [
    "##### `calcMultiplicityData()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "V_DYktU1Oncp"
   },
   "outputs": [],
   "source": [
    "def calcMultiplicityData(objectsBkg, objectsSigList):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "    objectsBkg:       pT of all objects for each background event; ndarray of shape\n",
    "                      (Nb, 19) where Nb is the number of background events\n",
    "    objectsSigList:   List of arrays of pT of all objects for each signal event;\n",
    "                      element of list is ndarray of shape (Ns, 19), where Ns, the\n",
    "                      number of signal events, varies depending on the signal type;\n",
    "                      signal types in list is 'sig_A', 'sig_h0', 'sig_hch', 'sig_LQ'\n",
    "  Outputs:\n",
    "    multBkgList:      List of arrays corresponding to electron, muon, jet, and total multiplicities\n",
    "    multSigList:      List of list of arrays corresponding to electron, muon, jet, and total multiplicities for each signal type\n",
    "                      E.g. multSigList[0] is the list of electron multiplicities for all signal types\n",
    "                      Total multiplicity is defined as multiplicity of all particle-type objects (i.e. excluding MET which is always present)\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Get multiplicities for background data --#\n",
    "  multElectrons_Bkg = np.count_nonzero(objectsBkg[:, 1:5], axis=1)\n",
    "  multMuons_Bkg     = np.count_nonzero(objectsBkg[:, 5:9], axis=1)\n",
    "  multJets_Bkg      = np.count_nonzero(objectsBkg[:, 9:19], axis=1)\n",
    "  multTotal_Bkg     = np.count_nonzero(objectsBkg[:, 1:19], axis=1) # Exclude MET since it is always present\n",
    "\n",
    "  multBkgList = [multElectrons_Bkg, multMuons_Bkg, multJets_Bkg, multTotal_Bkg]\n",
    "\n",
    "  #-- Get multiplicities for signal data --#\n",
    "  listMultElectrons_Sig, listMultMuons_Sig, listMultJets_Sig, listMultTotal_Sig = [],[],[],[]\n",
    "  nSignalCategories = len(objectsSigList)\n",
    "  for i in range(nSignalCategories):\n",
    "    objectsSig = objectsSigList[i]\n",
    "\n",
    "    listMultElectrons_Sig.append(np.count_nonzero(objectsSig[:, 1:5], axis=1))\n",
    "    listMultMuons_Sig.append(np.count_nonzero(objectsSig[:, 5:9], axis=1))\n",
    "    listMultJets_Sig.append(np.count_nonzero(objectsSig[:, 9:19], axis=1))\n",
    "    listMultTotal_Sig.append(np.count_nonzero(objectsSig[:, 1:19], axis=1))\n",
    "\n",
    "  multSigList = [listMultElectrons_Sig, listMultMuons_Sig, listMultJets_Sig, listMultTotal_Sig]\n",
    "\n",
    "  return multBkgList, multSigList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLhA5t-yRNB5"
   },
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9seIfw2pJNmq"
   },
   "source": [
    "## Misc. helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dK5LQhiZH0kv"
   },
   "source": [
    "##### `RGBAtoRGBAtuple()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Dfhj_RXcH-OG"
   },
   "outputs": [],
   "source": [
    "def RGBAtoRGBAtuple(color, TYPE='tuple'):\n",
    "  \"\"\"\n",
    "  Quick function to convert human RGBA to python RGBA tuple format. Example:\n",
    "     Human RGBA  = (120,15,116,1)\n",
    "     Python RGBA = RGBAtoRGBAtuple((120,15,116,1))\n",
    "\n",
    "  Inputs:\n",
    "    color:   Human RGBA tuple\n",
    "    TYPE:    Flag to indicate whether you want function to return a list or tuple; default is tuple\n",
    "  Outputs:\n",
    "    Python RGBA tuple (or list)\n",
    "  \"\"\"\n",
    "  r = color[0]/255\n",
    "  g = color[1]/255\n",
    "  b = color[2]/255\n",
    "  a = color[3]\n",
    "\n",
    "  if TYPE=='list':\n",
    "    return [r, g, b, a]\n",
    "  else:\n",
    "    return (r, g, b, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PB_iQRWuJae4"
   },
   "source": [
    "## Data plotting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsMMsL9qH_h7"
   },
   "source": [
    "##### `plotDataHists() `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "SZDecAowIMKl"
   },
   "outputs": [],
   "source": [
    "def plotDataHists(objectBkg, objectSigList, plotArgDict):\n",
    "  \"\"\"\n",
    "  Plot histograms of an object's pT, eta, phi for Signal and Signal+Background\n",
    "  for each signal case.\n",
    "\n",
    "  Inputs:\n",
    "    objectBkg:      A background event's object's (e.g. MET) pT, eta, phi;\n",
    "                    shape = (Nb, 3); Nb = number of background events\n",
    "    objectSigList:  A list of signal event object's (e.g. MET) pT, eta, phi for\n",
    "                    nCases number of signal cases; List of tuples with shapes\n",
    "                    (Ns, 3); Ns = number of signal events\n",
    "    plotArgDict:    Dictionary of plotting arguments (see example below)\n",
    "\n",
    "  Outputs:\n",
    "    Nothing returned; Show plot\n",
    "\n",
    "\n",
    "  Example plotArgDict:\n",
    "  # Define colors to use for 4 signal types\n",
    "      SIGNAL_COLOR_ARR = np.array([ RGBAtoRGBAtuple((231, 186, 81, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((140, 162, 82, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((165, 81, 148, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((214, 97, 107, 1), TYPE='list')\n",
    "                                  ])\n",
    "  # Or use a matplotlib color map\n",
    "      SIGNAL_COLOR_ARR = plt.colormaps['rainbow'].reversed()\n",
    "\n",
    "  # Then define dictionary as follows\n",
    "      plotArgDict = {}\n",
    "      plotArgDict['pltDim']             = (1,3) # i.e. 1 row, 3 columns\n",
    "      plotArgDict['xAxisLimsList']      = [(0, 1500), (-5, 5), (-np.pi, np.pi)]\n",
    "      plotArgDict['title']              = r'MET'\n",
    "      plotArgDict['nBins']              = 50\n",
    "      plotArgDict['CMAP']               = SIGNAL_COLOR_ARR\n",
    "      plotArgDict['sigObjectNameList']  = [r'$A$', r'$h^0$', r'$h^\\pm$', r'$LQ$']\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Preliminary Figure Setup --#\n",
    "  pltDim = plotArgDict['pltDim']\n",
    "  fig_size = (7*pltDim[1], 7*pltDim[0])\n",
    "  fig = plt.figure(constrained_layout=True, figsize=fig_size)\n",
    "  gs = GridSpec(pltDim[0], pltDim[1], figure=fig, hspace=0.1)\n",
    "  axes = []\n",
    "  for i in range(pltDim[1]):\n",
    "    axes.append(fig.add_subplot(gs[:, i]))\n",
    "\n",
    "  xLabelList = [r'$p_{\\rm T}$', r'$\\eta$', r'$\\phi$']\n",
    "\n",
    "  #-- Define color map --#\n",
    "  # Reference: https://stackoverflow.com/questions/38208700/matplotlib-plot-lines-with-colors-through-colormap\n",
    "  nCases    = len(objectSigList)  # Number of cases to plot\n",
    "  if isinstance(plotArgDict['CMAP'], np.ndarray) and (plotArgDict['CMAP'].shape[0]==nCases):\n",
    "    colorList = plotArgDict['CMAP']\n",
    "  else:\n",
    "    CMAP      = plotArgDict['CMAP']\n",
    "    colorList = CMAP(np.linspace(0,1,nCases))\n",
    "\n",
    "  #-- Combine data for S+B plots for all signal types --#\n",
    "  objectBkgSigList = []\n",
    "  for objectSig in objectSigList:\n",
    "    objectBkgSigList.append(np.concatenate((objectBkg, objectSig), axis=0))\n",
    "\n",
    "\n",
    "  #-- Loop over axes to make plots --#\n",
    "  for i in range(pltDim[1]):\n",
    "\n",
    "    ax = axes[i]\n",
    "\n",
    "    # Set axis and title information\n",
    "    xmin, xmax = plotArgDict['xAxisLimsList'][i]\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set(xlabel=xLabelList[i])\n",
    "    ax.xaxis.label.set_size(16)\n",
    "\n",
    "    if i==0:\n",
    "      ax.set(ylabel=r'Simulated events')\n",
    "      ax.yaxis.label.set_size(16)\n",
    "\n",
    "    if i==1:\n",
    "      ax.set_title(plotArgDict['title'], fontsize=20)\n",
    "\n",
    "    # Set bin information\n",
    "    bins = np.linspace(xmin, xmax, plotArgDict['nBins'])\n",
    "\n",
    "    #-- Plot background case --#\n",
    "    _, _, _,   = ax.hist(objectBkg[:,i], bins=bins, histtype = 'step', edgecolor='black', linestyle='-', linewidth=2, fill=False, log=True, label='Background')\n",
    "\n",
    "    #-- Loop over signal cases --#\n",
    "    for j in range(nCases):\n",
    "      objectBkgSig = objectBkgSigList[j]\n",
    "      objectSig    = objectSigList[j]\n",
    "\n",
    "      # Get data\n",
    "      SB = objectBkgSig[:,i]\n",
    "      S  = objectSig[:,i]\n",
    "\n",
    "      # Make plot\n",
    "      Slabel = plotArgDict['sigObjectNameList'][j]+' Signal'\n",
    "      SBlabel = Slabel+' + Background'\n",
    "      _, _, _,   = ax.hist(SB, bins=bins, histtype = 'step', edgecolor=colorList[j], linestyle='--', linewidth=2, fill=False, log=True, label=SBlabel)\n",
    "\n",
    "    if i==0:\n",
    "      ax.legend(loc='upper right')\n",
    "\n",
    "  #-- Show the plot --#\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhySvQshIyN_"
   },
   "source": [
    "##### `plotMultiplicityData() `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "hoBn1FAHRiQd"
   },
   "outputs": [],
   "source": [
    "def plotMultiplicityData(multBkgList, multSigList, plotArgDict):\n",
    "  \"\"\"\n",
    "  Plot histograms of the multiplicity of electrons, muons, and jets for Background and each Signal case.\n",
    "\n",
    "  Inputs:\n",
    "    multBkgList:      List of arrays corresponding to electron, muon, and jet multiplicities\n",
    "                      E.g. multBkgList[0] is an array of shape (Nb,) where  Nb = number of background events\n",
    "                      multBkgList[0][i] is the electron multiplicity for the ith event\n",
    "    multSigList:      List of list of arrays corresponding to electron, muon, and jet multiplicities for each signal type\n",
    "                      E.g. multSigList[0] is the list of electron multiplicities for all signal types\n",
    "                      multSigList[0][j] is an array of shape (Ns,) where Ns = number of signal events in the jth signal type\n",
    "                      multSigList[0][j][i] is the electron multiplicity for the ith event of signal type j\n",
    "    plotArgDict:    Dictionary of plotting arguments (see example below)\n",
    "\n",
    "  Outputs:\n",
    "    Nothing returned; Show plot\n",
    "\n",
    "\n",
    "  Example plotArgDict:\n",
    "  # Define colors to use for 4 signal types\n",
    "      SIGNAL_COLOR_ARR = np.array([ RGBAtoRGBAtuple((231, 186, 81, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((140, 162, 82, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((165, 81, 148, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((214, 97, 107, 1), TYPE='list')\n",
    "                                  ])\n",
    "  # Or use a matplotlib color map\n",
    "      SIGNAL_COLOR_ARR = plt.colormaps['rainbow'].reversed()\n",
    "\n",
    "  # Then define dictionary as follows\n",
    "      plotArgDict = {}\n",
    "      plotArgDict['pltDim']             = (1,3) # i.e. 1 row, 3 columns\n",
    "      plotArgDict['xAxisLimsList']      = [(-0.5, 5.5), (-0.5, 5.5), (-0.5, 10.5)]\n",
    "      plotArgDict['title']              = r'Multiplicity'\n",
    "      plotArgDict['CMAP']               = SIGNAL_COLOR_ARR\n",
    "      plotArgDict['sigObjectNameList']  = [r'$A$', r'$h^0$', r'$h^\\pm$', r'$LQ$']\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Preliminary Figure Setup --#\n",
    "  pltDim = plotArgDict['pltDim']\n",
    "  fig_size = (7*pltDim[1], 7*pltDim[0])\n",
    "  fig = plt.figure(constrained_layout=True, figsize=fig_size)\n",
    "  gs = GridSpec(pltDim[0], pltDim[1], figure=fig, hspace=0.1)\n",
    "  axes = []\n",
    "  for i in range(pltDim[1]):\n",
    "    axes.append(fig.add_subplot(gs[:, i]))\n",
    "\n",
    "  xLabelList = [r'$e$ multiplicity', r'$\\mu$ multiplicity', r'${\\rm jet}$ multiplicity']\n",
    "\n",
    "\n",
    "  #-- Define color map --#\n",
    "  # Reference: https://stackoverflow.com/questions/38208700/matplotlib-plot-lines-with-colors-through-colormap\n",
    "  nCases    = len(multSigList[0])  # Number of cases to plot\n",
    "  if isinstance(plotArgDict['CMAP'], np.ndarray) and (plotArgDict['CMAP'].shape[0]==nCases):\n",
    "    colorList = plotArgDict['CMAP']\n",
    "  else:\n",
    "    CMAP      = plotArgDict['CMAP']\n",
    "    colorList = CMAP(np.linspace(0,1,nCases))\n",
    "\n",
    "\n",
    "  #-- Loop over axes to make plots --#\n",
    "  # i=0 => Electrons\n",
    "  # i=1 => Muons\n",
    "  # i=2 => Jets\n",
    "  for i in range(pltDim[1]):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # Set axis and title information\n",
    "    xmin, xmax = plotArgDict['xAxisLimsList'][i]\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set(xlabel=xLabelList[i])\n",
    "    ax.xaxis.label.set_size(16)\n",
    "\n",
    "    if i==0:\n",
    "      ax.set(ylabel=r'Percent of simulated events')\n",
    "      ax.yaxis.label.set_size(16)\n",
    "\n",
    "    if i==1:\n",
    "      ax.set_title(plotArgDict['title'], fontsize=20)\n",
    "\n",
    "    # Set bin information\n",
    "    if i!=2:\n",
    "      bins = np.linspace(0, 5, 6)-0.5\n",
    "    else:\n",
    "      bins = np.linspace(0, 11, 12)-0.5\n",
    "\n",
    "    #-- Plot background case --#\n",
    "    _, _, _,   = ax.hist(multBkgList[i], bins=bins, histtype = 'step', edgecolor='black', linestyle='-', linewidth=2, fill=False, log=True, label='Background', density=True)\n",
    "\n",
    "    #-- Loop over signal cases --#\n",
    "    for j in range(nCases):\n",
    "      multSigList_ = multSigList[i]\n",
    "\n",
    "      # Make plot\n",
    "      Slabel = plotArgDict['sigObjectNameList'][j]+' Signal'\n",
    "      _, _, _,   = ax.hist(multSigList_[j], bins=bins, histtype = 'step', edgecolor=colorList[j], linestyle='--', linewidth=2, fill=False, log=True, label=Slabel, density=True)\n",
    "\n",
    "    if i==2:\n",
    "      ax.legend(loc='upper right')\n",
    "\n",
    "  #-- Show the plot --#\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `plotDataAugHists()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDataAugHists(objectBkg, objectAugBkg, plotArgDict):\n",
    "    \"\"\"\n",
    "    Plot histograms of an object's pT, eta, phi for Background and Augmented Bkg.\n",
    "\n",
    "    Inputs:\n",
    "        objectBkg:      A background event's object's (e.g. MET) pT, eta, phi;\n",
    "                        shape = (Nb, 3); Nb = number of background events\n",
    "        objectAugBkg:   An augmented background event's object's (e.g. MET) pT, eta, phi;\n",
    "                        shape = (Ns, 3); Ns = number of augmented background events (fake signal)\n",
    "        plotArgDict:    Dictionary of plotting arguments (see example below)\n",
    "\n",
    "    Outputs:\n",
    "        Nothing returned; Show plot\n",
    "\n",
    "\n",
    "    Example plotArgDict:\n",
    "        plotArgDict = {}\n",
    "        plotArgDict['pltDim']             = (1,3) # i.e. 1 row, 3 columns\n",
    "        plotArgDict['xAxisLimsList']      = [(0, 1500), (-5, 5), (-np.pi, np.pi)]\n",
    "        plotArgDict['title']              = r'MET'\n",
    "        plotArgDict['nBins']              = 50\n",
    "        plotArgDict['sigObjectNameList']  = [r'$A$', r'$h^0$', r'$h^\\pm$', r'$LQ$']\n",
    "    \"\"\"\n",
    "    #-- Preliminary Figure Setup --#\n",
    "    pltDim = plotArgDict['pltDim']\n",
    "    fig_size = (7*pltDim[1], 7*pltDim[0])\n",
    "    fig = plt.figure(constrained_layout=True, figsize=fig_size)\n",
    "    gs = GridSpec(pltDim[0], pltDim[1], figure=fig, hspace=0.1)\n",
    "    axes = []\n",
    "    for i in range(pltDim[1]):\n",
    "        axes.append(fig.add_subplot(gs[:, i]))\n",
    "\n",
    "    xLabelList = [r'$p_{\\rm T}$', r'$\\eta$', r'$\\phi$']\n",
    "\n",
    "    #-- Loop over axes to make plots --#\n",
    "    for i in range(pltDim[1]):\n",
    "\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Set axis and title information\n",
    "        xmin, xmax = plotArgDict['xAxisLimsList'][i]\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        ax.set(xlabel=xLabelList[i])\n",
    "        ax.xaxis.label.set_size(16)\n",
    "\n",
    "        if i==0:\n",
    "            ax.set(ylabel=r'Simulated events')\n",
    "            ax.yaxis.label.set_size(16)\n",
    "\n",
    "        if i==1:\n",
    "            ax.set_title(plotArgDict['title'], fontsize=20)\n",
    "\n",
    "        # Set bin information\n",
    "        bins = np.linspace(xmin, xmax, plotArgDict['nBins'])\n",
    "\n",
    "        #-- Plot background case --#\n",
    "        _, _, _,   = ax.hist(objectBkg[:,i], bins=bins, histtype = 'step', edgecolor='black', linestyle='-', linewidth=2, fill=False, log=True, label='Background')\n",
    "        _, _, _,   = ax.hist(objectAugBkg[:,i], bins=bins, histtype = 'step', edgecolor='purple', linestyle='--', linewidth=2, fill=False, log=True, label='Augmented Background')\n",
    "\n",
    "        if i==0:\n",
    "            ax.legend(loc='upper right')\n",
    "\n",
    "    #-- Show the plot --#\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P50l8xVPJs2w"
   },
   "source": [
    "## OT results plotting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wl2ft0VRILr5"
   },
   "source": [
    "##### `plotScoreHists() `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "vHZAGzmOIZH0"
   },
   "outputs": [],
   "source": [
    "def plotScoreHists(scoreBkg, scoreSigList, plotArgDict):\n",
    "  \"\"\"\n",
    "  Plot a 1D histogram of the anomaly score for the background and each signal case\n",
    "\n",
    "  Inputs:\n",
    "    scoreBkg:      An array of anomaly scores for a set of background events;\n",
    "                   shape = (Nb, ); Nb = number of background events\n",
    "    scoreSigList:  A list of arrays of anomaly scores for nCases number of signal cases;\n",
    "                   List of length nCases of arrays with shapes (Ns, 3);\n",
    "                   Ns = number of signal events\n",
    "    plotArgDict:    Dictionary of plotting arguments (see example below)\n",
    "\n",
    "  Outputs:\n",
    "    Nothing returned; Show plot\n",
    "\n",
    "  Example plotArgDict:\n",
    "  # Define colors to use for 4 signal types\n",
    "      SIGNAL_COLOR_ARR = np.array([ RGBAtoRGBAtuple((231, 186, 81, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((140, 162, 82, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((165, 81, 148, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((214, 97, 107, 1), TYPE='list')\n",
    "                                  ])\n",
    "  # Or use a matplotlib color map\n",
    "      SIGNAL_COLOR_ARR = plt.colormaps['rainbow'].reversed()\n",
    "\n",
    "  # Then define dictionary as follows\n",
    "  plotArgDict = {}\n",
    "  plotArgDict['pltDim']             = (3,3)\n",
    "  plotArgDict['xAxisLims']          = (0, 17500)\n",
    "  plotArgDict['xLabel']             = r'Anomaly Score: $W_2^2(\\cdot, \\cdot)$'\n",
    "  plotArgDict['yAxisLims']          = (1, 1e4)\n",
    "  plotArgDict['yLabel']             = r'Counts'\n",
    "  plotArgDict['title']              = r''\n",
    "  plotArgDict['nBins']              = 100\n",
    "  plotArgDict['logY']               = True\n",
    "  plotArgDict['CMAP']               = SIGNAL_COLOR_ARR\n",
    "  plotArgDict['sigObjectNameList']  = [r'$A$', r'$h^0$', r'$h^\\pm$', r'$LQ$']\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Preliminary Figure Setup --#\n",
    "  pltDim = plotArgDict['pltDim']\n",
    "  fig_size = (3*pltDim[1], 3*pltDim[0])\n",
    "\n",
    "  fig = plt.figure(constrained_layout=False, figsize=fig_size)\n",
    "\n",
    "  gs = GridSpec(pltDim[0], pltDim[1], figure=fig, hspace=0.1)\n",
    "  ax = fig.add_subplot(gs[:, :])\n",
    "\n",
    "  xmin, xmax = plotArgDict['xAxisLims']\n",
    "  ax.set_xlim(xmin, xmax)\n",
    "  ax.set(xlabel=plotArgDict['xLabel'])\n",
    "  ax.xaxis.label.set_size(16)\n",
    "\n",
    "  ymin, ymax = plotArgDict['yAxisLims']\n",
    "  ax.set_ylim(ymin, ymax)\n",
    "  ax.set(ylabel=plotArgDict['yLabel'])\n",
    "  ax.yaxis.label.set_size(16)\n",
    "\n",
    "  ax.set_title(plotArgDict['title'], fontsize=20)\n",
    "\n",
    "  if 'density' in  list(plotArgDict.keys()):\n",
    "    DENSITY = plotArgDict['density']\n",
    "  else:\n",
    "    DENSITY = False\n",
    "\n",
    "  #-- Define color map --#\n",
    "  # https://stackoverflow.com/questions/38208700/matplotlib-plot-lines-with-colors-through-colormap\n",
    "  nCases    = len(scoreSigList)  # Number of cases to plot\n",
    "  if isinstance(plotArgDict['CMAP'], np.ndarray) and (plotArgDict['CMAP'].shape[0]==nCases):\n",
    "    colorList = plotArgDict['CMAP']\n",
    "  else:\n",
    "    CMAP      = plotArgDict['CMAP']\n",
    "    colorList = CMAP(np.linspace(0,1,nCases))\n",
    "\n",
    "  #-- Make histogram plot --#\n",
    "  binsArr = np.linspace(xmin, xmax, plotArgDict['nBins'])\n",
    "  _, _, _   = ax.hist(scoreBkg, bins=binsArr, histtype = 'step', edgecolor='black', linestyle='-', linewidth=2, fill=False, log=True, label='Background', density=DENSITY)\n",
    "\n",
    "  for i in range(nCases):\n",
    "    label = plotArgDict['sigObjectNameList'][i]\n",
    "    _, _, _,   = ax.hist(scoreSigList[i], bins=binsArr, histtype = 'step', edgecolor=colorList[i], linestyle='--', linewidth=2, fill=False, log=True, label=label, density=DENSITY)\n",
    "\n",
    "  #-- Show the plot with legend --#\n",
    "  ax.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGBfwbvcIyE6"
   },
   "source": [
    "##### `plotMaxIndividualOTScoresPerEvent() `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "nLxrE_n2I2H3"
   },
   "outputs": [],
   "source": [
    "def plotMaxIndividualOTScoresPerEvent(indxs, maxArr, plotArgDict):\n",
    "  \"\"\"\n",
    "  Plot the (regulated) Significance Improvement (SI) curve from values\n",
    "  precalculated using the calcROCmetrics() function.\n",
    "\n",
    "      x-axis is the Signal (Acceptance) Efficiency <=> TPR <=> \\eps_S\n",
    "      y-axis is the (regulated) Significance Improvement <=> SI := TPR/sqrt(FPR + SIreg) <=> SI := eps_S/sqrt(eps_B + SIreg)\n",
    "\n",
    "  Inputs:\n",
    "    tprList:      List of TPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  tprList[i] is an array of shape (Q,) with Q>2\n",
    "    SIList:       List of SI arrays for each background to signal type pairing; Length=nCases\n",
    "                  SIList[i] is an array of shape (Q,) with Q>2\n",
    "    plotArgDict:  Dictionary of plotting arguments (see example below)\n",
    "\n",
    "\n",
    "  Example plotArgDict:\n",
    "  # Define colors to use for 4 signal types\n",
    "      SIGNAL_COLOR_ARR = np.array([ RGBAtoRGBAtuple((231, 186, 81, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((140, 162, 82, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((165, 81, 148, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((214, 97, 107, 1), TYPE='list')\n",
    "                                  ])\n",
    "  # Or use a matplotlib color map\n",
    "      SIGNAL_COLOR_ARR = plt.colormaps['rainbow'].reversed()\n",
    "\n",
    "  # Then define dictionary as follows\n",
    "    plotArgDict = {}\n",
    "    plotArgDict['pltDim']    = (3,3)\n",
    "    plotArgDict['xAxisLims'] = (0, 1.05)\n",
    "    plotArgDict['xLabel']    = r'Event Pairs'\n",
    "    plotArgDict['yAxisLims'] = (0, 10)\n",
    "    plotArgDict['yLabel']    = r'Max OT distance'\n",
    "    plotArgDict['title']     = r'wBS_sig_A'\n",
    "    plotArgDict['coreColorList'] = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']\n",
    "  \"\"\"\n",
    "  nEventPairs = maxArr.shape[0]\n",
    "\n",
    "  #-- Preliminary Figure Setup --#\n",
    "  pltDim = plotArgDict['pltDim']\n",
    "  fig_size = (3*pltDim[1], 3*pltDim[0])\n",
    "\n",
    "  fig = plt.figure(constrained_layout=False, figsize=fig_size)\n",
    "\n",
    "  gs = GridSpec(pltDim[0], pltDim[1], figure=fig, hspace=0.1)\n",
    "  ax = fig.add_subplot(gs[:, :])\n",
    "\n",
    "  xmin, xmax = plotArgDict['xAxisLims']\n",
    "  ax.set_xlim(xmin, xmax)\n",
    "  ax.set(xlabel=plotArgDict['xLabel'])\n",
    "  ax.xaxis.label.set_size(16)\n",
    "\n",
    "  ymin, ymax = plotArgDict['yAxisLims']\n",
    "  ax.set_ylim(ymin, ymax)\n",
    "  ax.set(ylabel=plotArgDict['yLabel'])\n",
    "  ax.yaxis.label.set_size(16)\n",
    "\n",
    "  ax.set_title(plotArgDict['title'], fontsize=20)\n",
    "\n",
    "  #-- Get color list for plotting --#\n",
    "  coreColorList = plotArgDict['coreColorList']\n",
    "  colorList     = []\n",
    "  for i in range(maxArr.shape[0]):\n",
    "    indx = indxs[i]\n",
    "    colorList.append(coreColorList[indx])\n",
    "\n",
    "  #-- Make plot --#\n",
    "  eventPairsArr = np.arange(nEventPairs)\n",
    "  ax.scatter(eventPairsArr, maxArr, color=colorList)\n",
    "\n",
    "  #-- Plot key --#\n",
    "  deltaY = (ymax - ymin)\n",
    "  deltaX = (xmax - xmin)\n",
    "  ax.text(xmin + 0.20*deltaX, ymin + 0.95*deltaY, r'IOT$_{\\rm MET}$', color=coreColorList[0], fontsize=16, fontweight='bold')\n",
    "  ax.text(xmin + 0.40*deltaX, ymin + 0.95*deltaY,   r'IOT$_{\\rm e}$', color=coreColorList[1], fontsize=16, fontweight='bold')\n",
    "  ax.text(xmin + 0.60*deltaX, ymin + 0.95*deltaY, r'IOT$_{\\rm \\mu}$', color=coreColorList[2], fontsize=16, fontweight='bold')\n",
    "  ax.text(xmin + 0.80*deltaX, ymin + 0.95*deltaY, r'IOT$_{\\rm jet}$', color=coreColorList[3], fontsize=16, fontweight='bold')\n",
    "\n",
    "  #-- Show plot --#\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MTLkICDIUK9"
   },
   "source": [
    "##### `plotROCcurve() `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "bhpb46o_Ieoh"
   },
   "outputs": [],
   "source": [
    "def plotROCcurve(aucList, fprList, tprList, plotArgDict, TYPE='Classic'):\n",
    "  \"\"\"\n",
    "  Plot ROC curves from values precalculated using the calcROCmetrics() function.\n",
    "\n",
    "  Inputs:\n",
    "    aucList:      List of AUC scores for each background to signal type pairing; Length=nCases\n",
    "    fprList:      List of FPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  fprList[i] is an array of shape (Q,) with Q>2\n",
    "    tprList:      List of TPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  tprList[i] is an array of shape (Q,) with Q>2\n",
    "    plotArgDict:  Dictionary of plotting arguments (see example below)\n",
    "    TYPE:         TYPE of ROC curve to plot; choices are 'Classic' (default) or 'Modern'\n",
    "                  (see below for explanation)\n",
    "\n",
    "\n",
    "  Explanation of TYPE choices:\n",
    "    For all TYPE choices the x-axis is defined as the Signal (Acceptance)\n",
    "    Efficiency <=> TPR <=> \\eps_S\n",
    "\n",
    "    if TYPE == 'Classic':\n",
    "        y-axis is the Background Rejection Efficiency <=> TNR <=> 1 - FPR <=> 1 - \\eps_B\n",
    "    otherwise:\n",
    "        y-axis is the Background (Acceptance) Efficiency <=> FPR <=> \\eps_B\n",
    "\n",
    "\n",
    "  Example plotArgDict:\n",
    "  # Define colors to use for 4 signal types\n",
    "      SIGNAL_COLOR_ARR = np.array([ RGBAtoRGBAtuple((231, 186, 81, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((140, 162, 82, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((165, 81, 148, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((214, 97, 107, 1), TYPE='list')\n",
    "                                  ])\n",
    "  # Or use a matplotlib color map\n",
    "      SIGNAL_COLOR_ARR = plt.colormaps['rainbow'].reversed()\n",
    "\n",
    "  # Then define dictionary as follows (assuming TYPE == 'Classic')\n",
    "      plotArgDict = {}\n",
    "      plotArgDict['pltDim']    = (3,3)\n",
    "      plotArgDict['xAxisLims'] = (0, 1.05)\n",
    "      plotArgDict['xLabel']    = r'Signal Efficiency (TPR)' # OR r'$\\eps_S$'\n",
    "      plotArgDict['yAxisLims'] = (0, 1.05)\n",
    "      plotArgDict['yLabel']    = r'Background Rejection (TNR)' # OR r'$1 - \\eps_B$'\n",
    "      plotArgDict['title']     = r'ROC curve, $W_2^2(\\cdot, \\cdot)$ anomaly score'\n",
    "      plotArgDict['CMAP']               = SIGNAL_COLOR_ARR\n",
    "      plotArgDict['sigObjectNameList']  = [r'$A$', r'$h^0$', r'$h^\\pm$', r'$LQ$']\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Preliminary Figure Setup --#\n",
    "  pltDim = plotArgDict['pltDim']\n",
    "  fig_size = (3*pltDim[1], 3*pltDim[0])\n",
    "\n",
    "  fig = plt.figure(constrained_layout=False, figsize=fig_size)\n",
    "\n",
    "  gs = GridSpec(pltDim[0], pltDim[1], figure=fig, hspace=0.1)\n",
    "  ax = fig.add_subplot(gs[:, :])\n",
    "\n",
    "  xmin, xmax = plotArgDict['xAxisLims']\n",
    "  ax.set_xlim(xmin, xmax)\n",
    "  ax.set(xlabel=plotArgDict['xLabel'])\n",
    "  ax.xaxis.label.set_size(16)\n",
    "\n",
    "  ymin, ymax = plotArgDict['yAxisLims']\n",
    "  ax.set_ylim(ymin, ymax)\n",
    "  ax.set(ylabel=plotArgDict['yLabel'])\n",
    "  ax.yaxis.label.set_size(16)\n",
    "\n",
    "  ax.set_title(plotArgDict['title'], fontsize=20)\n",
    "\n",
    "  #-- Define color map --#\n",
    "  # https://stackoverflow.com/questions/38208700/matplotlib-plot-lines-with-colors-through-colormap\n",
    "  nCases    = len(aucList)  # Number of cases to plot\n",
    "  if isinstance(plotArgDict['CMAP'], np.ndarray) and (plotArgDict['CMAP'].shape[0]==nCases):\n",
    "    colorList = plotArgDict['CMAP']\n",
    "  else:\n",
    "    CMAP      = plotArgDict['CMAP']\n",
    "    colorList = CMAP(np.linspace(0,1,nCases))\n",
    "\n",
    "  #-- Loop over signal cases --#\n",
    "  for i in range(nCases):\n",
    "\n",
    "    #-- Get ROC curve components --#\n",
    "    auc, fpr, tpr = aucList[i], fprList[i], tprList[i]\n",
    "\n",
    "    #-- Plot ROC curve --#\n",
    "    legendLabel = plotArgDict['sigObjectNameList'][i]+': AUC='+str(auc)\n",
    "    if TYPE == 'Classic':\n",
    "      tnr = 1. - fpr\n",
    "      _   = ax.plot(tpr, tnr, color=colorList[i], linestyle='-', linewidth=2, label=legendLabel)\n",
    "    else:\n",
    "      _   = ax.plot(tpr, fpr, color=colorList[i], linestyle='-', linewidth=2, label=legendLabel)\n",
    "\n",
    "  #-- Show the plot with legend --#\n",
    "  if TYPE == 'Classic':\n",
    "    ax.legend(loc='lower left')\n",
    "  else:\n",
    "    ax.legend(loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdpzFhu3IeDF"
   },
   "source": [
    "##### `plotInvROCcurve() `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ipojTrvbIl5a"
   },
   "outputs": [],
   "source": [
    "def plotInvROCcurve(aucList, fprInvList, tprList, plotArgDict):\n",
    "  \"\"\"\n",
    "  Plot FPR inverse curves from values precalculated using the calcROCmetrics() function.\n",
    "\n",
    "    x-axis is the Signal (Acceptance) Efficiency <=> TPR <=> \\eps_S\n",
    "    y-axis is the inverted the Background (Acceptance) Efficiency <=> FPR <=> \\eps_B\n",
    "\n",
    "  NOTE: This is often also called a \"ROC curve\" however this is misleading because\n",
    "  the AUC is NOT the area under this curve, so it is NOT a ROC curve.\n",
    "\n",
    "  Inputs:\n",
    "    aucList:      List of AUC scores for each background to signal type pairing; Length=nCases\n",
    "    fprInvList:   List of inverse FPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  fprInvList[i] is a masked array of shape (Q,) with Q>2 with division by zero cases masked\n",
    "    tprList:      List of TPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  tprList[i] is an array of shape (Q,) with Q>2\n",
    "    plotArgDict:  Dictionary of plotting arguments (see example below)\n",
    "\n",
    "\n",
    "  Example plotArgDict:\n",
    "  # Define colors to use for 4 signal types\n",
    "      SIGNAL_COLOR_ARR = np.array([ RGBAtoRGBAtuple((231, 186, 81, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((140, 162, 82, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((165, 81, 148, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((214, 97, 107, 1), TYPE='list')\n",
    "                                  ])\n",
    "  # Or use a matplotlib color map\n",
    "      SIGNAL_COLOR_ARR = plt.colormaps['rainbow'].reversed()\n",
    "\n",
    "  # Then define dictionary as follows\n",
    "      plotArgDict = {}\n",
    "      plotArgDict['pltDim']    = (3,3)\n",
    "      plotArgDict['xAxisLims'] = (0, 1.05)\n",
    "      plotArgDict['xLabel']    = r'$\\epsilon_S$ (TPR)'\n",
    "      plotArgDict['yAxisLims'] = (1, 1e4)\n",
    "      plotArgDict['yLabel']    = r'$\\epsilon_B^{-1}$ (FPR$^{-1}$)'\n",
    "      plotArgDict['title']     = r'$W_2^2(\\cdot, \\cdot)$ anomaly score performance'\n",
    "      plotArgDict['CMAP']               = SIGNAL_COLOR_ARR\n",
    "      plotArgDict['sigObjectNameList']  = [r'$A$', r'$h^0$', r'$h^\\pm$', r'$LQ$']\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Preliminary Figure Setup --#\n",
    "  pltDim = plotArgDict['pltDim']\n",
    "  fig_size = (3*pltDim[1], 3*pltDim[0])\n",
    "\n",
    "  fig = plt.figure(constrained_layout=False, figsize=fig_size)\n",
    "\n",
    "  gs = GridSpec(pltDim[0], pltDim[1], figure=fig, hspace=0.1)\n",
    "  ax = fig.add_subplot(gs[:, :])\n",
    "\n",
    "  xmin, xmax = plotArgDict['xAxisLims']\n",
    "  ax.set_xlim(xmin, xmax)\n",
    "  ax.set(xlabel=plotArgDict['xLabel'])\n",
    "  ax.xaxis.label.set_size(16)\n",
    "\n",
    "  ymin, ymax = plotArgDict['yAxisLims']\n",
    "  ax.set_ylim(ymin, ymax)\n",
    "  ax.set_yscale('log')\n",
    "  ax.set(ylabel=plotArgDict['yLabel'])\n",
    "  ax.yaxis.label.set_size(16)\n",
    "\n",
    "  ax.set_title(plotArgDict['title'], fontsize=20)\n",
    "\n",
    "  #-- Define color map --#\n",
    "  nCases    = len(aucList)  # Number of cases to plot\n",
    "  if isinstance(plotArgDict['CMAP'], np.ndarray) and (plotArgDict['CMAP'].shape[0]==nCases):\n",
    "    colorList = plotArgDict['CMAP']\n",
    "  else:\n",
    "    CMAP      = plotArgDict['CMAP']\n",
    "    colorList = CMAP(np.linspace(0,1,nCases)) # https://stackoverflow.com/questions/38208700/matplotlib-plot-lines-with-colors-through-colormap\n",
    "\n",
    "  #-- Loop over signal cases --#\n",
    "  for i in range(nCases):\n",
    "\n",
    "    #-- Get ROC curve components --#\n",
    "    auc, fprInv, tpr = aucList[i], fprInvList[i], tprList[i]\n",
    "\n",
    "    #-- Plot ROC curve --#\n",
    "    legendLabel = plotArgDict['sigObjectNameList'][i]+': AUC='+str(auc)\n",
    "    _ = ax.plot(tpr, fprInv, color=colorList[i], linestyle='-', linewidth=2, label=legendLabel)\n",
    "\n",
    "  #-- Show the plot with legend --#\n",
    "  ax.legend(loc='upper right')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHfO_CiTIlOM"
   },
   "source": [
    "##### `plotSIcurve() `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "dPDGx_D9Iy9y"
   },
   "outputs": [],
   "source": [
    "def plotSIcurve(tprList, SIList, plotArgDict):\n",
    "  \"\"\"\n",
    "   Plot the (regulated) Significance Improvement (SI) curve from values\n",
    "   precalculated using the calcROCmetrics() function.\n",
    "\n",
    "      x-axis is the Signal (Acceptance) Efficiency <=> TPR <=> \\eps_S\n",
    "      y-axis is the (regulated) Significance Improvement <=> SI := TPR/sqrt(FPR + SIreg) <=> SI := eps_S/sqrt(eps_B + SIreg)\n",
    "\n",
    "  Inputs:\n",
    "    tprList:      List of TPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  tprList[i] is an array of shape (Q,) with Q>2\n",
    "    SIList:       List of SI arrays for each background to signal type pairing; Length=nCases\n",
    "                  SIList[i] is an array of shape (Q,) with Q>2\n",
    "    plotArgDict:  Dictionary of plotting arguments (see example below)\n",
    "\n",
    "\n",
    "  Example plotArgDict:\n",
    "  # Define colors to use for 4 signal types\n",
    "      SIGNAL_COLOR_ARR = np.array([ RGBAtoRGBAtuple((231, 186, 81, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((140, 162, 82, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((165, 81, 148, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((214, 97, 107, 1), TYPE='list')\n",
    "                                  ])\n",
    "  # Or use a matplotlib color map\n",
    "      SIGNAL_COLOR_ARR = plt.colormaps['rainbow'].reversed()\n",
    "\n",
    "  # Then define dictionary as follows\n",
    "    plotArgDict = {}\n",
    "    plotArgDict['pltDim']    = (3,3)\n",
    "    plotArgDict['xAxisLims'] = (0, 1.05)\n",
    "    plotArgDict['xLabel']    = r'$\\epsilon_S$ (TPR)'\n",
    "    plotArgDict['yAxisLims'] = (0, 10)\n",
    "    plotArgDict['yLabel']    = r'$\\epsilon_S/ \\sqrt{\\epsilon_B}$ (SI)'\n",
    "    plotArgDict['title']     = r'SI Curve, $W_2^2(\\cdot, \\cdot)$ anomaly score'\n",
    "    plotArgDict['CMAP']               = SIGNAL_COLOR_ARR\n",
    "    plotArgDict['sigObjectNameList']  = [r'$A$', r'$h^0$', r'$h^\\pm$', r'$LQ$']\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Preliminary Figure Setup --#\n",
    "  pltDim = plotArgDict['pltDim']\n",
    "  fig_size = (3*pltDim[1], 3*pltDim[0])\n",
    "\n",
    "  fig = plt.figure(constrained_layout=False, figsize=fig_size)\n",
    "\n",
    "  gs = GridSpec(pltDim[0], pltDim[1], figure=fig, hspace=0.1)\n",
    "  ax = fig.add_subplot(gs[:, :])\n",
    "\n",
    "  xmin, xmax = plotArgDict['xAxisLims']\n",
    "  ax.set_xlim(xmin, xmax)\n",
    "  ax.set(xlabel=plotArgDict['xLabel'])\n",
    "  ax.xaxis.label.set_size(16)\n",
    "\n",
    "  ymin, ymax = plotArgDict['yAxisLims']\n",
    "  ax.set_ylim(ymin, ymax)\n",
    "  ax.set(ylabel=plotArgDict['yLabel'])\n",
    "  ax.yaxis.label.set_size(16)\n",
    "\n",
    "  ax.set_title(plotArgDict['title'], fontsize=20)\n",
    "\n",
    "  #-- Define color map --#\n",
    "  # https://stackoverflow.com/questions/38208700/matplotlib-plot-lines-with-colors-through-colormap\n",
    "  nCases    = len(tprList)  # Number of cases to plot\n",
    "  if isinstance(plotArgDict['CMAP'], np.ndarray) and (plotArgDict['CMAP'].shape[0]==nCases):\n",
    "    colorList = plotArgDict['CMAP']\n",
    "  else:\n",
    "    CMAP      = plotArgDict['CMAP']\n",
    "    colorList = CMAP(np.linspace(0,1,nCases))\n",
    "\n",
    "  #-- Loop over signal cases --#\n",
    "  for i in range(nCases):\n",
    "\n",
    "    #-- Get ROC curve components --#\n",
    "    si, tpr = SIList[i], tprList[i]\n",
    "\n",
    "    #-- Plot ROC curve --#\n",
    "    legendLabel = plotArgDict['sigObjectNameList'][i]\n",
    "    _ = ax.plot(tpr, si, color=colorList[i], linestyle='-', linewidth=2, label=legendLabel)\n",
    "\n",
    "  #-- Show the plot with legend --#\n",
    "  ax.legend(loc='upper right')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metric plotting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".#! TBD: Versions of these plot types with error band, so they accept mean std of quantity and plot quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `plotROCcurve_errorBand() `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotROCcurve_errorBand(av_fprList, std_fprList, plotArgDict, TYPE='Classic'):\n",
    "  \"\"\"\n",
    "  Plot ROC curves with error bands from values precalculated using the calcROCmetrics(..., INTERPOLATE=True) function.\n",
    "\n",
    "  Inputs:\n",
    "    av_fprList:   List of average FPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  av_fprList[i] is an array of shape (Q,) with Q>2\n",
    "    std_fprList:  List of std FPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  std_fprList[i] is an array of shape (Q,) with Q>2\n",
    "    plotArgDict:  Dictionary of plotting arguments (see example below)\n",
    "    TYPE:         TYPE of ROC curve to plot; choices are 'Classic' (default) or 'Modern'\n",
    "                  (see below for explanation)\n",
    "\n",
    "\n",
    "  Explanation of TYPE choices:\n",
    "    For all TYPE choices the x-axis is defined as the Signal (Acceptance)\n",
    "    Efficiency <=> TPR <=> \\eps_S\n",
    "\n",
    "    if TYPE == 'Classic':\n",
    "        y-axis is the Background Rejection Efficiency <=> TNR <=> 1 - FPR <=> 1 - \\eps_B\n",
    "    otherwise:\n",
    "        y-axis is the Background (Acceptance) Efficiency <=> FPR <=> \\eps_B\n",
    "\n",
    "\n",
    "  Example plotArgDict:\n",
    "  # Define colors to use for 4 signal types\n",
    "      SIGNAL_COLOR_ARR = np.array([ RGBAtoRGBAtuple((231, 186, 81, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((140, 162, 82, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((165, 81, 148, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((214, 97, 107, 1), TYPE='list')\n",
    "                                  ])\n",
    "  # Or use a matplotlib color map\n",
    "      SIGNAL_COLOR_ARR = plt.colormaps['rainbow'].reversed()\n",
    "\n",
    "  # Then define dictionary as follows (assuming TYPE == 'Classic')\n",
    "      plotArgDict = {}\n",
    "      plotArgDict['pltDim']    = (3,3)\n",
    "      plotArgDict['xAxisLims'] = (0, 1.05)\n",
    "      plotArgDict['xLabel']    = r'Signal Efficiency (TPR)' # OR r'$\\eps_S$'\n",
    "      plotArgDict['yAxisLims'] = (0, 1.05)\n",
    "      plotArgDict['yLabel']    = r'Background Rejection (TNR)' # OR r'$1 - \\eps_B$'\n",
    "      plotArgDict['title']     = r'ROC curve, $W_2^2(\\cdot, \\cdot)$ anomaly score'\n",
    "      plotArgDict['CMAP']               = SIGNAL_COLOR_ARR\n",
    "      plotArgDict['sigObjectNameList']  = [r'$A$', r'$h^0$', r'$h^\\pm$', r'$LQ$']\n",
    "  \"\"\"\n",
    "  #-- Set base TPR --#\n",
    "  base_tpr = np.linspace(0, 1, 101)\n",
    "\n",
    "  #-- Preliminary Figure Setup --#\n",
    "  pltDim = plotArgDict['pltDim']\n",
    "  fig_size = (3*pltDim[1], 3*pltDim[0])\n",
    "\n",
    "  fig = plt.figure(constrained_layout=False, figsize=fig_size)\n",
    "\n",
    "  gs = GridSpec(pltDim[0], pltDim[1], figure=fig, hspace=0.1)\n",
    "  ax = fig.add_subplot(gs[:, :])\n",
    "\n",
    "  xmin, xmax = plotArgDict['xAxisLims']\n",
    "  ax.set_xlim(xmin, xmax)\n",
    "  ax.set(xlabel=plotArgDict['xLabel'])\n",
    "  ax.xaxis.label.set_size(16)\n",
    "\n",
    "  ymin, ymax = plotArgDict['yAxisLims']\n",
    "  ax.set_ylim(ymin, ymax)\n",
    "  ax.set(ylabel=plotArgDict['yLabel'])\n",
    "  ax.yaxis.label.set_size(16)\n",
    "\n",
    "  ax.set_title(plotArgDict['title'], fontsize=20)\n",
    "\n",
    "  #-- Define color map --#\n",
    "  # https://stackoverflow.com/questions/38208700/matplotlib-plot-lines-with-colors-through-colormap\n",
    "  nCases    = len(av_fprList)  # Number of cases to plot\n",
    "  if isinstance(plotArgDict['CMAP'], np.ndarray) and (plotArgDict['CMAP'].shape[0]==nCases):\n",
    "    colorList = plotArgDict['CMAP']\n",
    "  else:\n",
    "    CMAP      = plotArgDict['CMAP']\n",
    "    colorList = CMAP(np.linspace(0,1,nCases))\n",
    "\n",
    "  #-- Loop over signal cases --#\n",
    "  for i in range(nCases):\n",
    "\n",
    "    #-- Get ROC curve components --#\n",
    "    av_fpr, std_fpr, tpr = av_fprList[i], std_fprList[i], base_tpr\n",
    "\n",
    "    #-- Get appropriate shading color --#\n",
    "    colorAlpha = list(colorList[i])\n",
    "    colorAlpha[3] = 0.5\n",
    "    colorAlpha = tuple(colorAlpha)\n",
    "\n",
    "    #-- Plot ROC curve --#\n",
    "    legendLabel = plotArgDict['sigObjectNameList'][i]\n",
    "    if TYPE == 'Classic':\n",
    "      av_tnr = 1. - av_fpr\n",
    "      _   = ax.plot(tpr, av_tnr, color=colorList[i], linestyle='-', linewidth=2, label=legendLabel)\n",
    "      _   = ax.fill_between(tpr, av_tnr-std_fpr, av_tnr+std_fpr, color=colorAlpha) # Note: std_tnr = std_fpr\n",
    "    else:\n",
    "      _   = ax.plot(tpr, av_fpr, color=colorList[i], linestyle='-', linewidth=2, label=legendLabel)\n",
    "      _   = ax.fill_between(tpr, av_fpr-std_fpr, av_fpr+std_fpr, color=colorAlpha)\n",
    "\n",
    "\n",
    "  #-- Show the plot with legend --#\n",
    "  if TYPE == 'Classic':\n",
    "    ax.legend(loc='lower left')\n",
    "  else:\n",
    "    ax.legend(loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `plotInvROCcurve_errorBand() `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotInvROCcurve_errorBand(av_fprInvList, std_fprInvList, plotArgDict):\n",
    "  \"\"\"\n",
    "  Plot FPR inverse curves with error bands from values precalculated using the calcROCmetrics(..., INTERPOLATE=True) function.\n",
    "\n",
    "    x-axis is the Signal (Acceptance) Efficiency <=> TPR <=> \\eps_S\n",
    "    y-axis is the inverted the Background (Acceptance) Efficiency <=> FPR <=> \\eps_B\n",
    "\n",
    "  NOTE: This is often also called a \"ROC curve\" however this is misleading because\n",
    "  the AUC is NOT the area under this curve, so it is NOT a ROC curve.\n",
    "\n",
    "  Inputs:\n",
    "    av_fprList:   List of average FPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  av_fprList[i] is an array of shape (Q,) with Q>2\n",
    "    std_fprList:  List of std FPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  std_fprList[i] is an array of shape (Q,) with Q>2\n",
    "    plotArgDict:  Dictionary of plotting arguments (see example below)\n",
    "\n",
    "\n",
    "  Example plotArgDict:\n",
    "  # Define colors to use for 4 signal types\n",
    "      SIGNAL_COLOR_ARR = np.array([ RGBAtoRGBAtuple((231, 186, 81, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((140, 162, 82, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((165, 81, 148, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((214, 97, 107, 1), TYPE='list')\n",
    "                                  ])\n",
    "  # Or use a matplotlib color map\n",
    "      SIGNAL_COLOR_ARR = plt.colormaps['rainbow'].reversed()\n",
    "\n",
    "  # Then define dictionary as follows\n",
    "      plotArgDict = {}\n",
    "      plotArgDict['pltDim']    = (3,3)\n",
    "      plotArgDict['xAxisLims'] = (0, 1.05)\n",
    "      plotArgDict['xLabel']    = r'$\\epsilon_S$ (TPR)'\n",
    "      plotArgDict['yAxisLims'] = (1, 1e4)\n",
    "      plotArgDict['yLabel']    = r'$\\epsilon_B^{-1}$ (FPR$^{-1}$)'\n",
    "      plotArgDict['title']     = r'$W_2^2(\\cdot, \\cdot)$ anomaly score performance'\n",
    "      plotArgDict['CMAP']               = SIGNAL_COLOR_ARR\n",
    "      plotArgDict['sigObjectNameList']  = [r'$A$', r'$h^0$', r'$h^\\pm$', r'$LQ$']\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Set base TPR --#\n",
    "  base_tpr = np.linspace(0, 1, 101)\n",
    "\n",
    "  #-- Preliminary Figure Setup --#\n",
    "  pltDim = plotArgDict['pltDim']\n",
    "  fig_size = (3*pltDim[1], 3*pltDim[0])\n",
    "\n",
    "  fig = plt.figure(constrained_layout=False, figsize=fig_size)\n",
    "\n",
    "  gs = GridSpec(pltDim[0], pltDim[1], figure=fig, hspace=0.1)\n",
    "  ax = fig.add_subplot(gs[:, :])\n",
    "\n",
    "  xmin, xmax = plotArgDict['xAxisLims']\n",
    "  ax.set_xlim(xmin, xmax)\n",
    "  ax.set(xlabel=plotArgDict['xLabel'])\n",
    "  ax.xaxis.label.set_size(16)\n",
    "\n",
    "  ymin, ymax = plotArgDict['yAxisLims']\n",
    "  ax.set_ylim(ymin, ymax)\n",
    "  ax.set_yscale('log')\n",
    "  ax.set(ylabel=plotArgDict['yLabel'])\n",
    "  ax.yaxis.label.set_size(16)\n",
    "\n",
    "  ax.set_title(plotArgDict['title'], fontsize=20)\n",
    "\n",
    "  #-- Define color map --#\n",
    "  nCases    = len(av_fprInvList)  # Number of cases to plot\n",
    "  if isinstance(plotArgDict['CMAP'], np.ndarray) and (plotArgDict['CMAP'].shape[0]==nCases):\n",
    "    colorList = plotArgDict['CMAP']\n",
    "  else:\n",
    "    CMAP      = plotArgDict['CMAP']\n",
    "    colorList = CMAP(np.linspace(0,1,nCases)) # https://stackoverflow.com/questions/38208700/matplotlib-plot-lines-with-colors-through-colormap\n",
    "\n",
    "  #-- Loop over signal cases --#\n",
    "  for i in range(nCases):\n",
    "\n",
    "    #-- Get ROC curve components --#\n",
    "    av_fprInv, std_fprInv, tpr = av_fprInvList[i], std_fprInvList[i], base_tpr\n",
    "\n",
    "    #-- Get appropriate shading color --#\n",
    "    colorAlpha = list(colorList[i])\n",
    "    colorAlpha[3] = 0.5\n",
    "    colorAlpha = tuple(colorAlpha)\n",
    "\n",
    "    #-- Plot ROC curve --#\n",
    "    legendLabel = plotArgDict['sigObjectNameList'][i]\n",
    "    _ = ax.plot(tpr, av_fprInv, color=colorList[i], linestyle='-', linewidth=2, label=legendLabel)\n",
    "    _ = ax.fill_between(tpr, av_fprInv-std_fprInv, av_fprInv+std_fprInv, color=colorAlpha)\n",
    "\n",
    "  #-- Show the plot with legend --#\n",
    "  ax.legend(loc='upper right')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `plotSIcurve_errorBand() `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSIcurve_errorBand(av_SIList, std_SIList, plotArgDict):\n",
    "  \"\"\"\n",
    "   Plot the (regulated) Significance Improvement (SI) curve with error bands from values precalculated using the calcROCmetrics(..., INTERPOLATE=True) function.\n",
    "\n",
    "      x-axis is the Signal (Acceptance) Efficiency <=> TPR <=> \\eps_S\n",
    "      y-axis is the (regulated) Significance Improvement <=> SI := TPR/sqrt(FPR + SIreg) <=> SI := eps_S/sqrt(eps_B + SIreg)\n",
    "\n",
    "  Inputs:\n",
    "    av_SIList:    List of average SI arrays for each background to signal type pairing; Length=nCases\n",
    "                  av_SIList[i] is an array of shape (Q,) with Q>2\n",
    "    std_SIList:   List of std SI arrays for each background to signal type pairing; Length=nCases\n",
    "                  std_SIList[i] is an array of shape (Q,) with Q>2\n",
    "    plotArgDict:  Dictionary of plotting arguments (see example below)\n",
    "\n",
    "\n",
    "  Example plotArgDict:\n",
    "  # Define colors to use for 4 signal types\n",
    "      SIGNAL_COLOR_ARR = np.array([ RGBAtoRGBAtuple((231, 186, 81, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((140, 162, 82, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((165, 81, 148, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((214, 97, 107, 1), TYPE='list')\n",
    "                                  ])\n",
    "  # Or use a matplotlib color map\n",
    "      SIGNAL_COLOR_ARR = plt.colormaps['rainbow'].reversed()\n",
    "\n",
    "  # Then define dictionary as follows\n",
    "    plotArgDict = {}\n",
    "    plotArgDict['pltDim']    = (3,3)\n",
    "    plotArgDict['xAxisLims'] = (0, 1.05)\n",
    "    plotArgDict['xLabel']    = r'$\\epsilon_S$ (TPR)'\n",
    "    plotArgDict['yAxisLims'] = (0, 10)\n",
    "    plotArgDict['yLabel']    = r'$\\epsilon_S/ \\sqrt{\\epsilon_B}$ (SI)'\n",
    "    plotArgDict['title']     = r'SI Curve, $W_2^2(\\cdot, \\cdot)$ anomaly score'\n",
    "    plotArgDict['CMAP']               = SIGNAL_COLOR_ARR\n",
    "    plotArgDict['sigObjectNameList']  = [r'$A$', r'$h^0$', r'$h^\\pm$', r'$LQ$']\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Set base TPR --#\n",
    "  base_tpr = np.linspace(0, 1, 101)\n",
    "\n",
    "  #-- Preliminary Figure Setup --#\n",
    "  pltDim = plotArgDict['pltDim']\n",
    "  fig_size = (3*pltDim[1], 3*pltDim[0])\n",
    "\n",
    "  fig = plt.figure(constrained_layout=False, figsize=fig_size)\n",
    "\n",
    "  gs = GridSpec(pltDim[0], pltDim[1], figure=fig, hspace=0.1)\n",
    "  ax = fig.add_subplot(gs[:, :])\n",
    "\n",
    "  xmin, xmax = plotArgDict['xAxisLims']\n",
    "  ax.set_xlim(xmin, xmax)\n",
    "  ax.set(xlabel=plotArgDict['xLabel'])\n",
    "  ax.xaxis.label.set_size(16)\n",
    "\n",
    "  ymin, ymax = plotArgDict['yAxisLims']\n",
    "  ax.set_ylim(ymin, ymax)\n",
    "  ax.set(ylabel=plotArgDict['yLabel'])\n",
    "  ax.yaxis.label.set_size(16)\n",
    "\n",
    "  ax.set_title(plotArgDict['title'], fontsize=20)\n",
    "\n",
    "  #-- Define color map --#\n",
    "  # https://stackoverflow.com/questions/38208700/matplotlib-plot-lines-with-colors-through-colormap\n",
    "  nCases    = len(av_SIList)  # Number of cases to plot\n",
    "  if isinstance(plotArgDict['CMAP'], np.ndarray) and (plotArgDict['CMAP'].shape[0]==nCases):\n",
    "    colorList = plotArgDict['CMAP']\n",
    "  else:\n",
    "    CMAP      = plotArgDict['CMAP']\n",
    "    colorList = CMAP(np.linspace(0,1,nCases))\n",
    "\n",
    "  #-- Loop over signal cases --#\n",
    "  for i in range(nCases):\n",
    "\n",
    "    #-- Get SI curve components --#\n",
    "    av_si, std_si, tpr = av_SIList[i], std_SIList[i], base_tpr\n",
    "\n",
    "    #-- Get appropriate shading color --#\n",
    "    colorAlpha = list(colorList[i])\n",
    "    colorAlpha[3] = 0.5\n",
    "    colorAlpha = tuple(colorAlpha)\n",
    "\n",
    "    #-- Plot SI curve --#\n",
    "    legendLabel = plotArgDict['sigObjectNameList'][i]\n",
    "    _ = ax.plot(tpr, av_si, color=colorList[i], linestyle='-', linewidth=2, label=legendLabel)\n",
    "    _ = ax.fill_between(tpr, av_si-std_si, av_si+std_si, color=colorAlpha)\n",
    "\n",
    "  #-- Show the plot with legend --#\n",
    "  ax.legend(loc='upper right')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single test run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `plotROCcurve() `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotROCcurve(aucList, fprList, tprList, plotArgDict, TYPE='Classic'):\n",
    "  \"\"\"\n",
    "  Plot ROC curves from values precalculated using the calcROCmetrics() function.\n",
    "\n",
    "  Inputs:\n",
    "    aucList:      List of AUC scores for each background to signal type pairing; Length=nCases\n",
    "    fprList:      List of FPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  fprList[i] is an array of shape (Q,) with Q>2\n",
    "    tprList:      List of TPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  tprList[i] is an array of shape (Q,) with Q>2\n",
    "    plotArgDict:  Dictionary of plotting arguments (see example below)\n",
    "    TYPE:         TYPE of ROC curve to plot; choices are 'Classic' (default) or 'Modern'\n",
    "                  (see below for explanation)\n",
    "\n",
    "\n",
    "  Explanation of TYPE choices:\n",
    "    For all TYPE choices the x-axis is defined as the Signal (Acceptance)\n",
    "    Efficiency <=> TPR <=> \\eps_S\n",
    "\n",
    "    if TYPE == 'Classic':\n",
    "        y-axis is the Background Rejection Efficiency <=> TNR <=> 1 - FPR <=> 1 - \\eps_B\n",
    "    otherwise:\n",
    "        y-axis is the Background (Acceptance) Efficiency <=> FPR <=> \\eps_B\n",
    "\n",
    "\n",
    "  Example plotArgDict:\n",
    "  # Define colors to use for 4 signal types\n",
    "      SIGNAL_COLOR_ARR = np.array([ RGBAtoRGBAtuple((231, 186, 81, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((140, 162, 82, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((165, 81, 148, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((214, 97, 107, 1), TYPE='list')\n",
    "                                  ])\n",
    "  # Or use a matplotlib color map\n",
    "      SIGNAL_COLOR_ARR = plt.colormaps['rainbow'].reversed()\n",
    "\n",
    "  # Then define dictionary as follows (assuming TYPE == 'Classic')\n",
    "      plotArgDict = {}\n",
    "      plotArgDict['pltDim']    = (3,3)\n",
    "      plotArgDict['xAxisLims'] = (0, 1.05)\n",
    "      plotArgDict['xLabel']    = r'Signal Efficiency (TPR)' # OR r'$\\eps_S$'\n",
    "      plotArgDict['yAxisLims'] = (0, 1.05)\n",
    "      plotArgDict['yLabel']    = r'Background Rejection (TNR)' # OR r'$1 - \\eps_B$'\n",
    "      plotArgDict['title']     = r'ROC curve, $W_2^2(\\cdot, \\cdot)$ anomaly score'\n",
    "      plotArgDict['CMAP']               = SIGNAL_COLOR_ARR\n",
    "      plotArgDict['sigObjectNameList']  = [r'$A$', r'$h^0$', r'$h^\\pm$', r'$LQ$']\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Preliminary Figure Setup --#\n",
    "  pltDim = plotArgDict['pltDim']\n",
    "  fig_size = (3*pltDim[1], 3*pltDim[0])\n",
    "\n",
    "  fig = plt.figure(constrained_layout=False, figsize=fig_size)\n",
    "\n",
    "  gs = GridSpec(pltDim[0], pltDim[1], figure=fig, hspace=0.1)\n",
    "  ax = fig.add_subplot(gs[:, :])\n",
    "\n",
    "  xmin, xmax = plotArgDict['xAxisLims']\n",
    "  ax.set_xlim(xmin, xmax)\n",
    "  ax.set(xlabel=plotArgDict['xLabel'])\n",
    "  ax.xaxis.label.set_size(16)\n",
    "\n",
    "  ymin, ymax = plotArgDict['yAxisLims']\n",
    "  ax.set_ylim(ymin, ymax)\n",
    "  ax.set(ylabel=plotArgDict['yLabel'])\n",
    "  ax.yaxis.label.set_size(16)\n",
    "\n",
    "  ax.set_title(plotArgDict['title'], fontsize=20)\n",
    "\n",
    "  #-- Define color map --#\n",
    "  # https://stackoverflow.com/questions/38208700/matplotlib-plot-lines-with-colors-through-colormap\n",
    "  nCases    = len(aucList)  # Number of cases to plot\n",
    "  if isinstance(plotArgDict['CMAP'], np.ndarray) and (plotArgDict['CMAP'].shape[0]==nCases):\n",
    "    colorList = plotArgDict['CMAP']\n",
    "  else:\n",
    "    CMAP      = plotArgDict['CMAP']\n",
    "    colorList = CMAP(np.linspace(0,1,nCases))\n",
    "\n",
    "  #-- Loop over signal cases --#\n",
    "  for i in range(nCases):\n",
    "\n",
    "    #-- Get ROC curve components --#\n",
    "    auc, fpr, tpr = aucList[i], fprList[i], tprList[i]\n",
    "\n",
    "    #-- Plot ROC curve --#\n",
    "    legendLabel = plotArgDict['sigObjectNameList'][i]+': AUC='+str(auc)\n",
    "    if TYPE == 'Classic':\n",
    "      tnr = 1. - fpr\n",
    "      _   = ax.plot(tpr, tnr, color=colorList[i], linestyle='-', linewidth=2, label=legendLabel)\n",
    "    else:\n",
    "      _   = ax.plot(tpr, fpr, color=colorList[i], linestyle='-', linewidth=2, label=legendLabel)\n",
    "\n",
    "  #-- Show the plot with legend --#\n",
    "  if TYPE == 'Classic':\n",
    "    ax.legend(loc='lower left')\n",
    "  else:\n",
    "    ax.legend(loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `plotInvROCcurve() `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotInvROCcurve(aucList, fprInvList, tprList, plotArgDict):\n",
    "  \"\"\"\n",
    "  Plot FPR inverse curves from values precalculated using the calcROCmetrics() function.\n",
    "\n",
    "    x-axis is the Signal (Acceptance) Efficiency <=> TPR <=> \\eps_S\n",
    "    y-axis is the inverted the Background (Acceptance) Efficiency <=> FPR <=> \\eps_B\n",
    "\n",
    "  NOTE: This is often also called a \"ROC curve\" however this is misleading because\n",
    "  the AUC is NOT the area under this curve, so it is NOT a ROC curve.\n",
    "\n",
    "  Inputs:\n",
    "    aucList:      List of AUC scores for each background to signal type pairing; Length=nCases\n",
    "    fprInvList:   List of inverse FPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  fprInvList[i] is a masked array of shape (Q,) with Q>2 with division by zero cases masked\n",
    "    tprList:      List of TPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  tprList[i] is an array of shape (Q,) with Q>2\n",
    "    plotArgDict:  Dictionary of plotting arguments (see example below)\n",
    "\n",
    "\n",
    "  Example plotArgDict:\n",
    "  # Define colors to use for 4 signal types\n",
    "      SIGNAL_COLOR_ARR = np.array([ RGBAtoRGBAtuple((231, 186, 81, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((140, 162, 82, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((165, 81, 148, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((214, 97, 107, 1), TYPE='list')\n",
    "                                  ])\n",
    "  # Or use a matplotlib color map\n",
    "      SIGNAL_COLOR_ARR = plt.colormaps['rainbow'].reversed()\n",
    "\n",
    "  # Then define dictionary as follows\n",
    "      plotArgDict = {}\n",
    "      plotArgDict['pltDim']    = (3,3)\n",
    "      plotArgDict['xAxisLims'] = (0, 1.05)\n",
    "      plotArgDict['xLabel']    = r'$\\epsilon_S$ (TPR)'\n",
    "      plotArgDict['yAxisLims'] = (1, 1e4)\n",
    "      plotArgDict['yLabel']    = r'$\\epsilon_B^{-1}$ (FPR$^{-1}$)'\n",
    "      plotArgDict['title']     = r'$W_2^2(\\cdot, \\cdot)$ anomaly score performance'\n",
    "      plotArgDict['CMAP']               = SIGNAL_COLOR_ARR\n",
    "      plotArgDict['sigObjectNameList']  = [r'$A$', r'$h^0$', r'$h^\\pm$', r'$LQ$']\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Preliminary Figure Setup --#\n",
    "  pltDim = plotArgDict['pltDim']\n",
    "  fig_size = (3*pltDim[1], 3*pltDim[0])\n",
    "\n",
    "  fig = plt.figure(constrained_layout=False, figsize=fig_size)\n",
    "\n",
    "  gs = GridSpec(pltDim[0], pltDim[1], figure=fig, hspace=0.1)\n",
    "  ax = fig.add_subplot(gs[:, :])\n",
    "\n",
    "  xmin, xmax = plotArgDict['xAxisLims']\n",
    "  ax.set_xlim(xmin, xmax)\n",
    "  ax.set(xlabel=plotArgDict['xLabel'])\n",
    "  ax.xaxis.label.set_size(16)\n",
    "\n",
    "  ymin, ymax = plotArgDict['yAxisLims']\n",
    "  ax.set_ylim(ymin, ymax)\n",
    "  ax.set_yscale('log')\n",
    "  ax.set(ylabel=plotArgDict['yLabel'])\n",
    "  ax.yaxis.label.set_size(16)\n",
    "\n",
    "  ax.set_title(plotArgDict['title'], fontsize=20)\n",
    "\n",
    "  #-- Define color map --#\n",
    "  nCases    = len(aucList)  # Number of cases to plot\n",
    "  if isinstance(plotArgDict['CMAP'], np.ndarray) and (plotArgDict['CMAP'].shape[0]==nCases):\n",
    "    colorList = plotArgDict['CMAP']\n",
    "  else:\n",
    "    CMAP      = plotArgDict['CMAP']\n",
    "    colorList = CMAP(np.linspace(0,1,nCases)) # https://stackoverflow.com/questions/38208700/matplotlib-plot-lines-with-colors-through-colormap\n",
    "\n",
    "  #-- Loop over signal cases --#\n",
    "  for i in range(nCases):\n",
    "\n",
    "    #-- Get ROC curve components --#\n",
    "    auc, fprInv, tpr = aucList[i], fprInvList[i], tprList[i]\n",
    "\n",
    "    #-- Plot ROC curve --#\n",
    "    legendLabel = plotArgDict['sigObjectNameList'][i]+': AUC='+str(auc)\n",
    "    _ = ax.plot(tpr, fprInv, color=colorList[i], linestyle='-', linewidth=2, label=legendLabel)\n",
    "\n",
    "  #-- Show the plot with legend --#\n",
    "  ax.legend(loc='upper right')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `plotSIcurve() `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSIcurve(tprList, SIList, plotArgDict):\n",
    "  \"\"\"\n",
    "   Plot the (regulated) Significance Improvement (SI) curve from values\n",
    "   precalculated using the calcROCmetrics() function.\n",
    "\n",
    "      x-axis is the Signal (Acceptance) Efficiency <=> TPR <=> \\eps_S\n",
    "      y-axis is the (regulated) Significance Improvement <=> SI := TPR/sqrt(FPR + SIreg) <=> SI := eps_S/sqrt(eps_B + SIreg)\n",
    "\n",
    "  Inputs:\n",
    "    tprList:      List of TPR arrays for each background to signal type pairing; Length=nCases\n",
    "                  tprList[i] is an array of shape (Q,) with Q>2\n",
    "    SIList:       List of SI arrays for each background to signal type pairing; Length=nCases\n",
    "                  SIList[i] is an array of shape (Q,) with Q>2\n",
    "    plotArgDict:  Dictionary of plotting arguments (see example below)\n",
    "\n",
    "\n",
    "  Example plotArgDict:\n",
    "  # Define colors to use for 4 signal types\n",
    "      SIGNAL_COLOR_ARR = np.array([ RGBAtoRGBAtuple((231, 186, 81, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((140, 162, 82, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((165, 81, 148, 1), TYPE='list'),\n",
    "                                    RGBAtoRGBAtuple((214, 97, 107, 1), TYPE='list')\n",
    "                                  ])\n",
    "  # Or use a matplotlib color map\n",
    "      SIGNAL_COLOR_ARR = plt.colormaps['rainbow'].reversed()\n",
    "\n",
    "  # Then define dictionary as follows\n",
    "    plotArgDict = {}\n",
    "    plotArgDict['pltDim']    = (3,3)\n",
    "    plotArgDict['xAxisLims'] = (0, 1.05)\n",
    "    plotArgDict['xLabel']    = r'$\\epsilon_S$ (TPR)'\n",
    "    plotArgDict['yAxisLims'] = (0, 10)\n",
    "    plotArgDict['yLabel']    = r'$\\epsilon_S/ \\sqrt{\\epsilon_B}$ (SI)'\n",
    "    plotArgDict['title']     = r'SI Curve, $W_2^2(\\cdot, \\cdot)$ anomaly score'\n",
    "    plotArgDict['CMAP']               = SIGNAL_COLOR_ARR\n",
    "    plotArgDict['sigObjectNameList']  = [r'$A$', r'$h^0$', r'$h^\\pm$', r'$LQ$']\n",
    "  \"\"\"\n",
    "\n",
    "  #-- Preliminary Figure Setup --#\n",
    "  pltDim = plotArgDict['pltDim']\n",
    "  fig_size = (3*pltDim[1], 3*pltDim[0])\n",
    "\n",
    "  fig = plt.figure(constrained_layout=False, figsize=fig_size)\n",
    "\n",
    "  gs = GridSpec(pltDim[0], pltDim[1], figure=fig, hspace=0.1)\n",
    "  ax = fig.add_subplot(gs[:, :])\n",
    "\n",
    "  xmin, xmax = plotArgDict['xAxisLims']\n",
    "  ax.set_xlim(xmin, xmax)\n",
    "  ax.set(xlabel=plotArgDict['xLabel'])\n",
    "  ax.xaxis.label.set_size(16)\n",
    "\n",
    "  ymin, ymax = plotArgDict['yAxisLims']\n",
    "  ax.set_ylim(ymin, ymax)\n",
    "  ax.set(ylabel=plotArgDict['yLabel'])\n",
    "  ax.yaxis.label.set_size(16)\n",
    "\n",
    "  ax.set_title(plotArgDict['title'], fontsize=20)\n",
    "\n",
    "  #-- Define color map --#\n",
    "  # https://stackoverflow.com/questions/38208700/matplotlib-plot-lines-with-colors-through-colormap\n",
    "  nCases    = len(tprList)  # Number of cases to plot\n",
    "  if isinstance(plotArgDict['CMAP'], np.ndarray) and (plotArgDict['CMAP'].shape[0]==nCases):\n",
    "    colorList = plotArgDict['CMAP']\n",
    "  else:\n",
    "    CMAP      = plotArgDict['CMAP']\n",
    "    colorList = CMAP(np.linspace(0,1,nCases))\n",
    "\n",
    "  #-- Loop over signal cases --#\n",
    "  for i in range(nCases):\n",
    "\n",
    "    #-- Get ROC curve components --#\n",
    "    si, tpr = SIList[i], tprList[i]\n",
    "\n",
    "    #-- Plot ROC curve --#\n",
    "    legendLabel = plotArgDict['sigObjectNameList'][i]\n",
    "    _ = ax.plot(tpr, si, color=colorList[i], linestyle='-', linewidth=2, label=legendLabel)\n",
    "\n",
    "  #-- Show the plot with legend --#\n",
    "  ax.legend(loc='upper right')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DU3JgR4r_5BF"
   },
   "source": [
    "# Machine Learning Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwN6yBxGAAJ9"
   },
   "source": [
    "## SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "MoudF5IfAFCD"
   },
   "outputs": [],
   "source": [
    "def SVM_ROC_Metrics(bkg_scores, sig_scores, C = 1.0, gamma = 'scale'):\n",
    "  np.random.shuffle(bkg_scores)\n",
    "  np.random.shuffle(sig_scores)\n",
    "\n",
    "  bkg_indicator = np.zeros(len(bkg_scores))\n",
    "  sig_indicator = np.ones(len(sig_scores))\n",
    "\n",
    "  bkg_x_train, bkg_x_test, bkg_y_train, bkg_y_test = train_test_split(bkg_scores, bkg_indicator, test_size=0.25, random_state=123)\n",
    "  bkg_x_train, bkg_x_test = np.array(bkg_x_train).reshape(-1, 1), np.array(bkg_x_test).reshape(-1, 1)\n",
    "\n",
    "  sig_x_train, sig_x_test, sig_y_train, sig_y_test = train_test_split(sig_scores, sig_indicator, test_size=0.25, random_state=123)\n",
    "  sig_x_train, sig_x_test = np.array(sig_x_train).reshape(-1, 1), np.array(sig_x_test).reshape(-1, 1)\n",
    "\n",
    "  x_train = np.concatenate((bkg_x_train, sig_x_train), axis = 0)\n",
    "  y_train = np.concatenate((bkg_y_train, sig_y_train))\n",
    "\n",
    "  x_test = np.concatenate((bkg_x_test, sig_x_test), axis = 0)\n",
    "  y_test = np.concatenate((bkg_y_test, sig_y_test))\n",
    "\n",
    "  # x = np.concatenate((bkg_scores, sig_scores))\n",
    "\n",
    "  # y = [0] * len(bkg_scores) + [1] * len(sig_scores)\n",
    "\n",
    "  # x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=123)\n",
    "  # x_train, x_test = np.array(x_train).reshape(-1, 1), np.array(x_test).reshape(-1, 1)\n",
    "\n",
    "  # Create the SVM with RBF kernel\n",
    "  clf = SVC(kernel='rbf', C = C, gamma = gamma)\n",
    "\n",
    "  # Train the SVM\n",
    "  clf.fit(x_train, y_train)\n",
    "\n",
    "  # Calibrate the SVC model\n",
    "  calibrated_clf = CalibratedClassifierCV(clf, method='sigmoid', cv='prefit')\n",
    "  calibrated_clf.fit(x_train, y_train)\n",
    "\n",
    "  # Get prediction probabilities for the test set\n",
    "  y_prob = calibrated_clf.predict_proba(x_test)[:,1]\n",
    "\n",
    "  # # Get predicted probabilities for the positive class (1 - Signal)\n",
    "  # y_prob = clf.predict_proba(x_test)[:, 1]\n",
    "\n",
    "  # Compute ROC curve and AUC\n",
    "  fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "  roc_auc = roc_auc_score(y_test, y_prob)\n",
    "  tnr = 1-fpr\n",
    "\n",
    "  return tnr,tpr,roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "g0ByrzEgFiIL"
   },
   "outputs": [],
   "source": [
    "def SVM_Classification_With_Best_Hyperparameters(bkg_scores, sig_scores):\n",
    "    C_range = [1,10]\n",
    "    gamma_range = [1,10]\n",
    "    auc_list = []\n",
    "    tnr_list = []\n",
    "    tpr_list = []\n",
    "\n",
    "    for C in C_range:\n",
    "      for gamma in gamma_range:\n",
    "        tnr,tpr,roc_auc = SVM_ROC_Metrics(bkg_scores, sig_scores, C, gamma)\n",
    "        tnr_list.append(tnr)\n",
    "        tpr_list.append(tpr)\n",
    "        auc_list.append(roc_auc)\n",
    "\n",
    "    max_index = auc_list.index(max(auc_list))\n",
    "\n",
    "    return tnr_list[max_index], tpr_list[max_index], auc_list[max_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZEsW88eXKbG"
   },
   "source": [
    "## kNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "IiFG6jUVXNZa"
   },
   "outputs": [],
   "source": [
    "def kNN_with_score_list(bkg_score, sig_score, train_number, val_number, test_number, sig_bkg_ratio, neighbor_list):\n",
    "  np.random.seed(123)\n",
    "  np.random.shuffle(bkg_score)\n",
    "  np.random.shuffle(sig_score)\n",
    "\n",
    "  bkg_indicator = np.zeros(len(bkg_score))\n",
    "  sig_indicator = np.ones(len(sig_score))\n",
    "\n",
    "  x_train = np.concatenate((bkg_score[:train_number],sig_score[:train_number*sig_bkg_ratio]))\n",
    "  x_train = x_train.reshape(-1,1)\n",
    "  y_train = np.concatenate((bkg_indicator[:train_number],sig_indicator[:train_number*sig_bkg_ratio]))\n",
    "\n",
    "  x_val = np.concatenate((bkg_score[train_number:train_number+val_number],sig_score[train_number*sig_bkg_ratio:(train_number+val_number)*sig_bkg_ratio]))\n",
    "  x_val = x_val.reshape(-1,1)\n",
    "  y_val = np.concatenate((bkg_indicator[train_number:train_number+val_number],sig_indicator[train_number*sig_bkg_ratio:(train_number+val_number)*sig_bkg_ratio]))\n",
    "\n",
    "  x_trainval = np.concatenate((bkg_score[:train_number+val_number],sig_score[:(train_number+val_number)*sig_bkg_ratio]))\n",
    "  x_trainval = x_trainval.reshape(-1,1)\n",
    "  y_trainval = np.concatenate((bkg_indicator[:train_number+val_number],sig_indicator[:(train_number+val_number)*sig_bkg_ratio]))\n",
    "\n",
    "  x_test = np.concatenate((bkg_score[train_number+val_number:train_number+val_number+test_number],sig_score[(train_number+val_number)*sig_bkg_ratio:(train_number+val_number+test_number)*sig_bkg_ratio]))\n",
    "  x_test = x_test.reshape(-1,1)\n",
    "  y_test = np.concatenate((bkg_indicator[train_number+val_number:train_number+val_number+test_number],sig_indicator[(train_number+val_number)*sig_bkg_ratio:(train_number+val_number+test_number)*sig_bkg_ratio]))\n",
    "\n",
    "  # print(len(bkg_score),len(sig_score))\n",
    "  # print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_trainval.shape, y_trainval.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "  models, pred_vals = [], []\n",
    "  for neighbor in neighbor_list:\n",
    "    # print(\"Processing neighbor k=\", neighbor)\n",
    "    model = KNeighborsClassifier(n_neighbors=neighbor)\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_val = model.predict_proba(x_val)[:,1]\n",
    "    models.append(model)\n",
    "    pred_vals.append(pred_val)\n",
    "\n",
    "  auc_list = []\n",
    "  for pred in pred_vals:\n",
    "    auc = roc_auc_score(y_val, pred)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "  max_index = auc_list.index(max(auc_list))\n",
    "  best_k = neighbor_list[max_index]\n",
    "  # print(max(auc_list))\n",
    "  # print(best_k)\n",
    "  # print(auc_list)\n",
    "\n",
    "  best_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "  best_model.fit(x_trainval, y_trainval)\n",
    "  best_pred = best_model.predict_proba(x_test)[:,1]\n",
    "  best_auc = roc_auc_score(y_test, best_pred)\n",
    "\n",
    "  return best_auc, best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Y0CDrjUnDFba"
   },
   "outputs": [],
   "source": [
    "def kNN_with_distance_matrix(l_matrix, labels, train_number, val_number, test_number, neighbor_list, AUC_list = False):\n",
    "    '''\n",
    "    Inputs:\n",
    "\n",
    "        l_matrix:          The distance matrix(2D np array) of the two types of jets. Shape:(njets, njets)\n",
    "                          (NOTE: This matrix must be symmetric and tracless for it to be a meaningful OT distance matrix)\n",
    "\n",
    "        labels:           An array of labels for which type of particle each row/column belongs to. Shape(njets,)\n",
    "\n",
    "        train_number:     The number of jets used for training the kNN model, set to be the first \"train_number\" of rows/cols\n",
    "\n",
    "        val_number:       The number of jets used for the validation process(determining the best number of neighbors), set to be the \"val_number\" of rows/cols right after the training rows/cols\n",
    "\n",
    "        test_number:      The number of jets used for the testing process, set to be the \"test_number\" of rows/cols right after the validation rows/cols\n",
    "\n",
    "        neighbor_list:   The list of neighbors wanted to be used for the kNN classification\n",
    "\n",
    "        AUC_list:         Default is False. When set to True, return the whole list of AUCs during the validation process\n",
    "\n",
    "    Outputs:\n",
    "\n",
    "        best_auc:         The AUC computed using the best-k-neighbor returned by the validation process.\n",
    "\n",
    "        auc_list:         The entire list of AUC computed during the validation process. Only returned if AUC_list is set to be True\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Split the distance matrix and labels into training, validation and testing sets\n",
    "    l_matrix_train         = l_matrix[:train_number, :train_number]\n",
    "    l_matrix_val_train     = l_matrix[train_number:train_number+val_number, :train_number]\n",
    "    l_matrix_trainval      = l_matrix[:train_number+val_number, :train_number+val_number]\n",
    "    l_matrix_test_trainval = l_matrix[train_number+val_number:test_number + train_number + val_number, :train_number+val_number]\n",
    "\n",
    "    # Split the labels into training, validation and testing sets\n",
    "    train_labels           = labels[:train_number]\n",
    "    val_labels             = labels[train_number:train_number+val_number]\n",
    "    trainval_labels        = labels[:train_number+val_number]\n",
    "    test_labels            = labels[train_number+val_number:test_number+train_number+val_number]\n",
    "\n",
    "    models, pred_vals = [], []\n",
    "\n",
    "    for neighbor in tqdm(neighbor_list, desc='Fitting Models'):\n",
    "        model = KNeighborsClassifier(n_neighbors=neighbor, metric='precomputed')\n",
    "        model.fit(l_matrix_train, train_labels)\n",
    "        pred_val = model.predict_proba(l_matrix_val_train)[:,1]\n",
    "        models.append(model)\n",
    "        pred_vals.append(pred_val)\n",
    "\n",
    "    auc_list = []\n",
    "\n",
    "    # Compute the AUC for each k-neighbor model\n",
    "    for pred in pred_vals:\n",
    "        auc = roc_auc_score(val_labels, pred)\n",
    "        auc_list.append(auc)\n",
    "\n",
    "    max_index = auc_list.index(max(auc_list))\n",
    "\n",
    "    # Get the best k-neighbor model\n",
    "    best_k_neighbor = neighbor_list[max_index]\n",
    "\n",
    "    best_model = KNeighborsClassifier(n_neighbors=best_k_neighbor, metric='precomputed')\n",
    "\n",
    "    # Train the best k-neighbor model\n",
    "    best_model.fit(l_matrix_trainval, trainval_labels)\n",
    "\n",
    "    # Get the prediction probabilities for the testing set\n",
    "    best_pred = best_model.predict_proba(l_matrix_test_trainval)[:,1]\n",
    "\n",
    "    kNN_metrics = kNN_ROC_metrics(test_labels, best_pred, Interpolate = True)\n",
    "    \n",
    "    best_auc = roc_auc_score(test_labels, best_pred)\n",
    "\n",
    "    if AUC_list == True:\n",
    "        return best_auc, best_k_neighbor, best_model, auc_list\n",
    "\n",
    "    else:\n",
    "        return best_auc, best_k_neighbor, best_model, kNN_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_cross_validation(l_matrix, labels, neighbor_list, k_fold):\n",
    "    '''\n",
    "    This function is basically a wrapper for the kNN_with_distance_matrix function, but with the addition of k-fold cross validation.\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "        l_matrix:          The distance matrix(2D np array) of the bkg and sig events. Shape:(n, n)\n",
    "        \n",
    "        labels:            An array of labels for which type of event(bkg/sig) each row/column belongs to. Shape(n,)\n",
    "        \n",
    "        neighbor_list:     The list of neighbors wanted to be used for the kNN classification\n",
    "        \n",
    "        k_fold:            The number of folds wanted to be used for the k-fold cross validation\n",
    "        \n",
    "    Outputs:\n",
    "    \n",
    "        np.mean(auc_list): The mean of the AUCs computed during the k-fold cross validation\n",
    "        \n",
    "        np.std(auc_list):  The standard deviation of the AUCs computed during the k-fold cross validation\n",
    "        \n",
    "        np.mean(best_k_list): The mean of the best-k-neighbors computed during the k-fold cross validation\n",
    "        \n",
    "        np.std(best_k_list): The standard deviation of the best-k-neighbors computed during the k-fold cross validation\n",
    "        \n",
    "        metrics_dict:      A dictionary containing all the metrics computed during the k-fold cross validation.\n",
    "    '''\n",
    "    length = l_matrix.shape[0]\n",
    "    folded_length = length//k_fold\n",
    "    index_list = []\n",
    "    \n",
    "    for i in range(0, k_fold):\n",
    "        index_list.append(list(range(i*folded_length, (i+1)*folded_length)))\n",
    "    \n",
    "    auc_list = []\n",
    "    best_k_list = []\n",
    "    metrics_dict = {}\n",
    "    \n",
    "    # perform k-fold cross validation\n",
    "    for i in range(0, k_fold):\n",
    "        new_index = index_list[i]\n",
    "        for j in range(1,k_fold):\n",
    "            new_index.extend(index_list[(i+j)%k_fold])\n",
    "        l_matrix_new = l_matrix[new_index,:][:,new_index]\n",
    "        labels_new = labels[new_index]\n",
    "        best_auc, best_k, _, kNN_metrics = kNN_with_distance_matrix(l_matrix_new, labels_new, folded_length*(k_fold-2), folded_length, folded_length, neighbor_list, AUC_list=False)\n",
    "        auc_list.append(best_auc)\n",
    "        best_k_list.append(best_k)\n",
    "        metrics_dict['repeat'+str(i)] = kNN_metrics\n",
    "        \n",
    "    return np.mean(auc_list), np.std(auc_list), np.mean(best_k_list), np.std(best_k_list), metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rNN_with_distance_matrix(l_matrix, labels, train_number, val_number, test_number, radius_list, AUC_list = False):\n",
    "    '''\n",
    "    Inputs:\n",
    "\n",
    "        l_matrix:          The distance matrix(2D np array) of the two types of jets. Shape:(njets, njets)\n",
    "                          (NOTE: This matrix must be symmetric and tracless for it to be a meaningful OT distance matrix)\n",
    "\n",
    "        labels:           An array of labels for which type of particle each row/column belongs to. Shape(njets,)\n",
    "\n",
    "        train_number:     The number of jets used for training the kNN model, set to be the first \"train_number\" of rows/cols\n",
    "\n",
    "        val_number:       The number of jets used for the validation process(determining the best number of neighbors), set to be the \"val_number\" of rows/cols right after the training rows/cols\n",
    "\n",
    "        test_number:      The number of jets used for the testing process, set to be the \"test_number\" of rows/cols right after the validation rows/cols\n",
    "\n",
    "        radius_list:      The list of radii wanted to be used for the kNN classification\n",
    "\n",
    "        AUC_list:         Default is False. When set to True, return the whole list of AUCs during the validation process\n",
    "\n",
    "    Outputs:\n",
    "\n",
    "        best_auc:         The AUC computed using the best-k-neighbor returned by the validation process.\n",
    "\n",
    "        auc_list:         The entire list of AUC computed during the validation process. Only returned if AUC_list is set to be True\n",
    "\n",
    "    '''\n",
    "\n",
    "    l_matrix_train         = l_matrix[:train_number, :train_number]\n",
    "    l_matrix_val_train     = l_matrix[train_number:train_number+val_number, :train_number]\n",
    "    l_matrix_trainval      = l_matrix[:train_number+val_number, :train_number+val_number]\n",
    "    l_matrix_test_trainval = l_matrix[train_number+val_number:test_number + train_number + val_number, :train_number+val_number]\n",
    "\n",
    "    train_labels           = labels[:train_number]\n",
    "    val_labels             = labels[train_number:train_number+val_number]\n",
    "    trainval_labels        = labels[:train_number+val_number]\n",
    "    test_labels            = labels[train_number+val_number:test_number+train_number+val_number]\n",
    "\n",
    "    models, pred_vals = [], []\n",
    "\n",
    "    for radius in tqdm(radius_list, desc='Fitting Models'):\n",
    "        model = RadiusNeighborsClassifier(radius=radius, metric='precomputed')\n",
    "        model.fit(l_matrix_train, train_labels)\n",
    "        pred_val = model.predict_proba(l_matrix_val_train)[:,1]\n",
    "        models.append(model)\n",
    "        pred_vals.append(pred_val)\n",
    "\n",
    "    auc_list = []\n",
    "\n",
    "    for pred in pred_vals:\n",
    "        auc = roc_auc_score(val_labels, pred)\n",
    "        auc_list.append(auc)\n",
    "\n",
    "    max_index = auc_list.index(max(auc_list))\n",
    "\n",
    "    best_radius = radius_list[max_index]\n",
    "\n",
    "    best_model = RadiusNeighborsClassifier(radius=best_radius, metric='precomputed')\n",
    "\n",
    "    best_model.fit(l_matrix_trainval, trainval_labels)\n",
    "\n",
    "    best_pred = best_model.predict_proba(l_matrix_test_trainval)[:,1]\n",
    "\n",
    "    best_auc = roc_auc_score(test_labels, best_pred)\n",
    "\n",
    "    if AUC_list == True:\n",
    "        return best_auc, best_radius, best_model, auc_list\n",
    "\n",
    "    else:\n",
    "        return best_auc, best_radius, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rNN_cross_validation(l_matrix, labels, radius_list, k_fold = 5):\n",
    "    '''\n",
    "    This function is basically a wrapper function around the rNN_with_distance_matrix function. It performs a k-fold cross validation\n",
    "    for the rNN model and returns the mean and standard deviation of the AUC and the best radius.\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "        l_matrix:          The distance matrix(2D np array) of bkg and sig events. Shape:(n, n)\n",
    "        \n",
    "        labels:            An array of labels for which type of event(bkg/sig) each row/column belongs to. Shape(n,)\n",
    "        \n",
    "        radius_list:       The list of radii wanted to be used for the rNN classification\n",
    "        \n",
    "        k_fold:            The number of folds wanted to be used for the cross validation process. Default is 5.\n",
    "        \n",
    "    Outputs:\n",
    "        \n",
    "        mean_auc:          The mean of the AUCs computed during the cross validation process\n",
    "        \n",
    "        std_auc:           The standard deviation of the AUCs computed during the cross validation process\n",
    "        \n",
    "        mean_best_radius:  The mean of the best radii computed during the cross validation process\n",
    "        \n",
    "        std_best_radius:   The standard deviation of the best radii computed during the cross validation process\n",
    "    '''\n",
    "    length = l_matrix.shape[0]\n",
    "    folded_length = length//k_fold\n",
    "    index_list = []\n",
    "    \n",
    "    for i in range(0, k_fold):\n",
    "        index_list.append(list(range(i*folded_length, (i+1)*folded_length)))\n",
    "    \n",
    "    auc_list = []\n",
    "    best_radius_list = []\n",
    "    \n",
    "    for i in range(0, k_fold):\n",
    "        new_index = index_list[i]\n",
    "        for j in range(1,k_fold):\n",
    "            new_index.extend(index_list[(i+j)%k_fold])\n",
    "        l_matrix_new = l_matrix[new_index,:][:,new_index]\n",
    "        labels_new = labels[new_index]\n",
    "        best_auc, best_radius, best_model = rNN_with_distance_matrix(l_matrix_new, labels_new, folded_length*(k_fold-2), folded_length, folded_length, radius_list, AUC_list=False)\n",
    "        auc_list.append(best_auc)\n",
    "        best_radius_list.append(best_radius)\n",
    "        \n",
    "    return np.mean(auc_list), np.std(auc_list), np.mean(best_radius_list), np.std(best_radius_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_with_distance_matrix(l_matrix, labels, train_number, val_number, test_number, gamma_list, C_list, kernel = 'rbf', AUC_list = False):\n",
    "    '''\n",
    "    Inputs:\n",
    "    \n",
    "        l_matrix:          The distance matrix(2D np array) of bkg and sig of events. Shape:(n, n)\n",
    "        \n",
    "        labels:            An array of labels for which type of event(bkg/sig) each row/column belongs to. Shape(n,)\n",
    "        \n",
    "        train_number:      The number of events used for training the SVM model, set to be the first \"train_number\" of rows/cols\n",
    "        \n",
    "        val_number:        The number of events used for the validation process(determining the best hyperparameters), set to be the \"val_number\" of rows/cols right after the training rows/cols\n",
    "        \n",
    "        test_number:       The number of events used for the testing process, set to be the \"test_number\" of rows/cols right after the validation rows/cols\n",
    "        \n",
    "        gamma_list:        The list of gamma values wanted to be used for the SVM classification\n",
    "        \n",
    "        C_list:            The list of C values wanted to be used for the SVM classification\n",
    "        \n",
    "        kernel:            The kernel used for the SVM classification. Default is 'rbf'\n",
    "        \n",
    "        AUC_list:          Default is False. When set to True, return the whole list of AUCs during the validation process\n",
    "        \n",
    "    Outputs:\n",
    "    \n",
    "        best_auc:          The AUC computed using the best hyperparameters returned by the validation process.\n",
    "        \n",
    "        best_gamma:        The best gamma hyperparameter returned by the validation process.\n",
    "        \n",
    "        best_C:            The best C hyperparameter returned by the validation process.\n",
    "        \n",
    "        best_model:        The best SVM model returned by the validation process.\n",
    "        \n",
    "        auc_list:          The entire list of AUC computed during the validation process. Only returned if AUC_list is set to be True\n",
    "    '''\n",
    "    models, pred_vals = [], []\n",
    "    \n",
    "    i = 0\n",
    "    train_labels           = labels[:train_number]\n",
    "    val_labels             = labels[train_number:train_number+val_number]\n",
    "    trainval_labels        = labels[:train_number+val_number]\n",
    "    test_labels            = labels[train_number+val_number:test_number+train_number+val_number]\n",
    "    \n",
    "    if kernel == 'rbf':\n",
    "        for gamma in gamma_list:\n",
    "        # for gamma in tqdm(gamma_list, desc='Gamma Loop'):\n",
    "            l_matrix_gamma = np.exp(-gamma*l_matrix)\n",
    "    \n",
    "            l_matrix_train         = l_matrix_gamma[:train_number, :train_number]\n",
    "            l_matrix_val_train     = l_matrix_gamma[train_number:train_number+val_number, :train_number]\n",
    "            l_matrix_trainval      = l_matrix_gamma[:train_number+val_number, :train_number+val_number]\n",
    "            l_matrix_test_trainval = l_matrix_gamma[train_number+val_number:test_number + train_number + val_number, :train_number+val_number]\n",
    "            models.append([])\n",
    "            pred_vals.append([])\n",
    "            \n",
    "            for C in C_list:\n",
    "                model = SVC(gamma=gamma, C=C, kernel='precomputed')\n",
    "                model.fit(l_matrix_train, train_labels)\n",
    "                pred_val = model.predict(l_matrix_val_train)\n",
    "                models[i].append(model)\n",
    "                pred_vals[i].append(pred_val)\n",
    "            \n",
    "            i += 1\n",
    "    \n",
    "    else:\n",
    "        l_matrix_train         = l_matrix[:train_number, :train_number]\n",
    "        l_matrix_val_train     = l_matrix[train_number:train_number+val_number, :train_number]\n",
    "        l_matrix_trainval      = l_matrix[:train_number+val_number, :train_number+val_number]\n",
    "        l_matrix_test_trainval = l_matrix[train_number+val_number:test_number + train_number + val_number, :train_number+val_number]\n",
    "\n",
    "        train_labels           = labels[:train_number]\n",
    "        val_labels             = labels[train_number:train_number+val_number]\n",
    "        trainval_labels        = labels[:train_number+val_number]\n",
    "        test_labels            = labels[train_number+val_number:test_number+train_number+val_number]\n",
    "    \n",
    "    auc_list = []\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for pred_row in pred_vals:\n",
    "        auc_list.append([])\n",
    "        for pred in pred_row:\n",
    "            auc = roc_auc_score(val_labels, pred)\n",
    "            auc_list[i].append(auc)\n",
    "        i += 1\n",
    "    \n",
    "    auc_array = np.array(auc_list)\n",
    "    max_index = np.unravel_index(auc_array.argmax(), auc_array.shape)\n",
    "    \n",
    "    best_gamma = gamma_list[max_index[0]]\n",
    "    best_C = C_list[max_index[1]]\n",
    "    \n",
    "    l_matrix_gamma = np.exp(-best_gamma*l_matrix)\n",
    "    \n",
    "    l_matrix_train         = l_matrix_gamma[:train_number, :train_number]\n",
    "    l_matrix_val_train     = l_matrix_gamma[train_number:train_number+val_number, :train_number]\n",
    "    l_matrix_trainval      = l_matrix_gamma[:train_number+val_number, :train_number+val_number]\n",
    "    l_matrix_test_trainval = l_matrix_gamma[train_number+val_number:test_number + train_number + val_number, :train_number+val_number]\n",
    "    \n",
    "    best_model = SVC(gamma=best_gamma, C = best_C, kernel='precomputed')\n",
    "    \n",
    "    best_model.fit(l_matrix_trainval, trainval_labels)\n",
    "    \n",
    "    best_pred = best_model.predict(l_matrix_test_trainval)\n",
    "    \n",
    "    best_auc = roc_auc_score(test_labels, best_pred)\n",
    "    \n",
    "    if AUC_list == True:\n",
    "        return best_auc, best_gamma, best_C, best_model, auc_list\n",
    "\n",
    "    else:\n",
    "        return best_auc, best_gamma, best_C, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_cross_validation(l_matrix, labels, gamma_list, C_list, kernel = 'rbf', k_fold = 5):\n",
    "    '''\n",
    "    This function is basically a wrapper function around the SVM_with_distance_matrix function. It performs a k-fold cross validation\n",
    "    for the SVM model and returns the mean and standard deviation of the AUC and the best hyperparameters.\n",
    "    \n",
    "    Inputs:\n",
    "        l_matrix:          The distance matrix(2D np array) of the signal and bkg samples. Shape:(n, n)\n",
    "        \n",
    "        labels:            An array of labels for which type of event(bkg/sig) each row/column belongs to. Shape(n,)\n",
    "        \n",
    "        gamma_list:        The list of gamma values wanted to be used for the SVM classification\n",
    "        \n",
    "        C_list:            The list of C values wanted to be used for the SVM classification\n",
    "        \n",
    "        kernel:            The kernel wanted to be used for the SVM classification. Default is 'rbf'\n",
    "        \n",
    "        k_fold:            The number of folds wanted to be used for the cross validation. Default is 5\n",
    "        \n",
    "    Outputs:\n",
    "        auc_list:          The list of AUCs computed during the cross validation process\n",
    "        \n",
    "        best_gamma_list:   The list of best gamma values computed during the cross validation process\n",
    "        \n",
    "        best_C_list:       The list of best C values computed during the cross validation process\n",
    "    '''\n",
    "    length = l_matrix.shape[0]\n",
    "    folded_length = length//k_fold\n",
    "    index_list = []\n",
    "    \n",
    "    for i in range(0, k_fold):\n",
    "        index_list.append(list(range(i*folded_length, (i+1)*folded_length)))\n",
    "    \n",
    "    auc_list = []\n",
    "    best_gamma_list = []\n",
    "    best_C_list = []\n",
    "    \n",
    "    for i in range(0, k_fold):\n",
    "        new_index = index_list[i]\n",
    "        for j in range(1,k_fold):\n",
    "            new_index.extend(index_list[(i+j)%k_fold])\n",
    "        l_matrix_new = l_matrix[new_index,:][:,new_index]\n",
    "        labels_new = labels[new_index]\n",
    "        \n",
    "        best_auc, best_gamma, best_C, best_model = SVM_with_distance_matrix(l_matrix_new, labels_new, folded_length*(k_fold-2), folded_length, folded_length, gamma_list, C_list, AUC_list=False)\n",
    "        \n",
    "        auc_list.append(best_auc)\n",
    "        best_gamma_list.append(best_gamma)\n",
    "        best_C_list.append(best_C)\n",
    "        \n",
    "    return auc_list, best_gamma_list, best_C_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneClassSVM_with_distance_matrix(train_matrix, test_matrix, test_labels, gamma, nu):\n",
    "    '''\n",
    "    Inputs:\n",
    "\n",
    "        train_matrix:     The train distance matrix(2D np array). Shape:(n, n)\n",
    "                          (NOTE: This matrix must be symmetric and tracless for it to be a meaningful OT distance matrix)\n",
    "\n",
    "        test_matrix:      The distance matrix(2D np array) of the two types of jets. Shape:(m, n)\n",
    "                          (NOTE: This matrix is usually not symmetric and tracelsss)\n",
    "\n",
    "        test_labels:      An array of binary labels for which type of particle each row/column belongs to. Shape(m,)\n",
    "\n",
    "        gamma:            The gamma parameter for the RBF kernel\n",
    "\n",
    "        nu:               The nu parameter for the OneClassSVM model\n",
    "        \n",
    "    Outputs:\n",
    "        \n",
    "        auc, f1_score, ROC_metrics: The performance metrics of the OneClassSVM model\n",
    "    '''\n",
    "    train_matrix_gamma = np.exp(-gamma*train_matrix)\n",
    "    test_matrix_gamma = np.exp(-gamma*test_matrix)\n",
    "    \n",
    "    model = svm.OneClassSVM(nu = nu, kernel='precomputed')\n",
    "    model.fit(train_matrix_gamma)\n",
    "    \n",
    "    pred = model.predict(test_matrix_gamma)\n",
    "    \n",
    "    ROC_metrics = kNN_ROC_metrics(test_labels, pred, Interpolate = True)\n",
    "    \n",
    "    auc = roc_auc_score(test_labels, pred)\n",
    "    f1_score = metrics.f1_score(test_labels, pred, average='micro')\n",
    "    \n",
    "    return auc, f1_score, ROC_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_ROC_metrics(labels, prediction_proba, SIreg=0.0001, Interpolate=False):\n",
    "    '''\n",
    "    Calculate ROC metrics for kNN classifier\n",
    "    Inputs:\n",
    "        labels:             An array of binary labels for background and signal.\n",
    "        prediction_proba:   An array of probabilities for each row/column being a signal jet. \n",
    "        SIreg:              The regularization parameter for the Significance Improvement (SI) curve. Default is 0.0001\n",
    "        Interpolate:        Default is False. When set to True, interpolate the ROC curve to have 101 points.\n",
    "    Outputs:\n",
    "        auc, fpr, tpr, si, fprInv, f1_score: The AUC, FPR, TPR, SI, FPR^{-1}, and F1 score of the ROC curve.\n",
    "    '''\n",
    "    fpr_raw, tpr_raw, _ = roc_curve(labels, prediction_proba)\n",
    "    \n",
    "    if Interpolate:\n",
    "        base_tpr = np.linspace(0, 1, 101) # 0.00, 0.01, ..., 1.0\n",
    "        tpr = base_tpr\n",
    "        fpr = np.interp(base_tpr, tpr_raw, fpr_raw)\n",
    "    else:\n",
    "        tpr = tpr_raw\n",
    "        fpr = fpr_raw\n",
    "    \n",
    "    auc = roc_auc_score(labels, prediction_proba)\n",
    "    \n",
    "    fpr_sqrt = np.sqrt(fpr + SIreg)\n",
    "    si = tpr/fpr_sqrt\n",
    "    \n",
    "    fpr_masked = ma.masked_where(fpr==0., fpr)\n",
    "    fprInv = 1./fpr_masked\n",
    "    \n",
    "    f1_score = (2*tpr)/(tpr + fpr + 1)\n",
    "    return auc, fpr, tpr, si, fprInv, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
